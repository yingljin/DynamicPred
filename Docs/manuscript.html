<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ying Jin" />

<meta name="date" content="2024-01-16" />

<title>Manuscript progress report</title>

<script src="manuscript_files/header-attrs-2.25/header-attrs.js"></script>
<script src="manuscript_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="manuscript_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="manuscript_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="manuscript_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="manuscript_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="manuscript_files/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="manuscript_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="manuscript_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="manuscript_files/navigation-1.1/tabsets.js"></script>
<script src="manuscript_files/navigation-1.1/codefolding.js"></script>
<link href="manuscript_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="manuscript_files/highlightjs-9.12.0/highlight.js"></script>
<script src="manuscript_files/kePrint-0.0.1/kePrint.js"></script>
<link href="manuscript_files/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Manuscript progress report</h1>
<h4 class="author">Ying Jin</h4>
<h4 class="date">2024-01-16</h4>

</div>


<div id="method" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Method</h1>
<div id="assumptions" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Assumptions</h2>
<ul>
<li>For each subject i in the population, a generalized outcome <span
class="math inline">\(Y_i(t)\)</span> is generated along a variable t
(for example, time), where <span class="math inline">\(t \in (0,
T)\)</span>.</li>
<li>The outcome, at any specific t, follows an exponential family
distribution characterized by a (latent) continuous function <span
class="math inline">\(\eta_i(t)\)</span>:</li>
</ul>
<p><span class="math display">\[g[E(Y_i(t))] = \eta_i(t) =
\beta_0(t)+b_i(t)\]</span></p>
<p><span class="math display">\[p(Y_i(t)) =
h(Y_i(t))exp\{\eta_i(t)T[Y_i(t)]-A(\eta_i(t))\}\]</span></p>
<ul>
<li>The continuous latent function consists of a population-level fixed
process and an individual-level random process</li>
</ul>
<p><span class="math display">\[\eta_i(t) =
\beta_0(t)+b_i(t)\]</span></p>
</div>
<div id="observed-data" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Observed data</h2>
<p>In practice we would observe the discrete realization of <span
class="math inline">\(\{Y_i(t), t\}\)</span> along a dense grid. For
simplicity, we assume the observation grid is regular (same across
sample). When we have J observations points in <span
class="math inline">\((0, T]\)</span>, then for the jth observation
point, we denote the corresponding value of t as <span
class="math inline">\(t_j\)</span>, and the corresponding outcome at
this point <span class="math inline">\(Y_i(t_j)\)</span>.</p>
</div>
<div id="fgfpca-algorithm" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> fGFPCA Algorithm</h2>
<div id="bin-data" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Bin data:</h3>
<p>Choose a proper bin width <span class="math inline">\(w\)</span>
considering model complexity and identifiability. For now letâ€™s say the
bins are equal-length and non-overlapping.</p>
<ul>
<li>Bin index <span class="math inline">\(s = 1...S\)</span></li>
<li>Index of bin midpoints <span class="math inline">\(m_s\)</span></li>
<li>Value of t corresponding to bin midpoints <span
class="math inline">\(t_{m_s}\)</span></li>
<li>Bin endpoints: <span class="math inline">\((t_{m_s}-\frac{w}{2},
t_{m_s}+\frac{w}{2}]\)</span></li>
</ul>
<pre class="r"><code>grid_exp &lt;- data.frame(t = seq(0, 1, by = 0.01), y = 0)
ggplot(grid_exp, aes(x=t, y=y))+
  geom_point(size = 0.5)</code></pre>
</div>
<div id="local-glmms" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Local GLMMs</h3>
<p>At the every bin, we fit a local intercept-only model:</p>
<p><span class="math display">\[g[E(Y_i(t_j))] =\eta_i(t_{m_s})=
\beta_0(t_{m_s})+b_i(t_{m_s})\]</span> where <span
class="math inline">\(t_j \in (t_{m_s}-\frac{w}{2},
t_{m_s}+\frac{w}{2}]\)</span>.</p>
<p>Here we are basically saying that the value of latent function is
constant within the same bin, which clearly is a misspecification of the
true latent process.</p>
<p>From the model above. we will be able to estimate a <span
class="math inline">\(\hat{\eta_i}(t_{m_s})\)</span> on the binned grid
for every individual in the training sample.</p>
</div>
<div id="fpca" class="section level3" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> FPCA</h3>
<p>Here, we fit a FPCA model on the <span
class="math inline">\(\hat{\eta_i}(t_{m_s})\)</span> obtained from step
2:</p>
<p><span class="math display">\[\hat{\eta}_i(t_{m_s}) =
f_0(t_{m_s})+\sum_{k=1}^K\xi_{ik}\phi_{k}(t_{m_s})+\epsilon_i(t_{m_s})\]</span></p>
<p>where <span class="math inline">\(\xi_{ik}\)</span> independently
follows normal distribution <span class="math inline">\(N(0,
\lambda_k)\)</span>, and <span
class="math inline">\(\epsilon_i(t_{m_s})\)</span> at each point follows
<span class="math inline">\(N(0, \sigma_2)\)</span>.</p>
<p>From this model, we will be able to obtain the following estimates
which are shared across population:</p>
<ul>
<li>Population mean <span
class="math inline">\(\hat{f_0}(t_{m_s})\)</span></li>
<li>Basis functions <span class="math inline">\(\hat{\mathbf{\Phi}} =
\{\hat{\phi}_1(t_{m_s}), ...,\hat{\phi}_K(t_{m_s}))\}\)</span></li>
<li>Estimates of variance of scores <span
class="math inline">\(\hat{\lambda}_1...\hat{\lambda}_K\)</span></li>
</ul>
</div>
<div id="projection-and-debias" class="section level3" number="1.3.4">
<h3><span class="header-section-number">1.3.4</span> Projection and
Debias</h3>
<p>The mean and basis functions are evaluated on the binned grid. To
extend it to the original measurement grid data was collected on, we
project the estimated eigenfunctions <span
class="math inline">\(\hat{\mathbf{\Phi}}\)</span> back use spline
basis. Now we have extend the <span
class="math inline">\(\hat{\phi}_k(t_{m_s})\)</span> to the original
grid <span class="math inline">\(\hat{\phi}_k(t_j)\)</span></p>
<p>Because of the misspecification of local GLMMs, the estimated
eigenfunctions and eigenvalues are also biased by a constant
multiplicative effect. Therefore, we use a GLMM to re-evaluate the mean
function, eigenfunctions and eigenvalues.</p>
</div>
</div>
<div id="out-of-sample-prediction" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Out-of-sample
prediction</h2>
<p>Now, letâ€™s assume we have a new subject <span
class="math inline">\(u\)</span> with <span
class="math inline">\(J_u\)</span> observations (<span
class="math inline">\(J_u &lt; J\)</span>). Then the log-likelihood of
this new subject would be:</p>
<p><span
class="math display">\[l_u=\sum_{t_j&lt;t_{J_u}}log(h(Y_u(t_j)))+\hat{\eta}_u(t_j)T(Y_u(t_j))-log(A[\hat{\eta}_u(t_j)])\]</span></p>
<p>where <span class="math inline">\(\hat{\eta}_u(t_j) =
\hat{f}_0(t_j)+\sum_{k=1}^K \xi_{uk}\hat{\phi}(t_j)\)</span>.</p>
<p>With estimates for the population-level parameters from fGFPCA
algorithms above, we can estimate <span
class="math inline">\(\xi_{uk}\)</span> by maximization of <span
class="math inline">\(l_u\)</span>. Direct maximization some times does
not have closed form solution. Numeric maximization methods seem not
very stable as well. So I have decided to used a Bayes approach (Laplace
Approximation):</p>
<ul>
<li>Prior distribution: <span class="math inline">\(\xi_{uk} \sim N(0,
\hat{\lambda}_k)\)</span></li>
<li>Posterior distribution: the likelihood of <span
class="math inline">\(l_u =l(Y_u(t_j)|\mathbf{\xi}_u)\)</span></li>
</ul>
<p>Laplace Approximation would get the posterior mode of <span
class="math inline">\(\xi_{uk}\)</span> through quadratic
approximation.</p>
</div>
</div>
<div id="larger-scale-simulation" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Larger-scale
simulation</h1>
<div id="simulation-set-up" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Simulation set
up</h2>
<p>Here we simulate binary data from cyclic latent process:</p>
<p><span class="math display">\[\begin{aligned}
Y_i(t) &amp; \sim Bernoulli(\frac{exp(\eta_i(t))}{1+exp(\eta_i(t))}) \\
\eta_i(t) &amp;= f_0(t)+ \xi_{i1}\sqrt{2}sin(2\pi
t)+\xi_{i2}\sqrt{2}cos(2\pi t)+\xi_{i3}\sqrt{2}sin(4\pi
t)+\xi_{i4}\sqrt{2}cos(4\pi t)
\end{aligned}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(t\)</span> is 1000 equal-spaced
observations points on <span class="math inline">\([0, 1]\)</span> (J =
1000).</li>
<li><span class="math inline">\(f_0(t)=0\)</span></li>
<li><span class="math inline">\(\xi_k \sim N(0, \lambda_k)\)</span>, and
<span class="math inline">\(\lambda_k = 1, 0.5, 0.25, 0.125\)</span> for
k = 1, 2, 3, 4 respectively.</li>
<li>Sample size <span class="math inline">\(N = 500\)</span></li>
<li>In the binning step, we bin every 10 observations</li>
<li>500 simulations were implemented</li>
</ul>
<pre class="r"><code>rand_id &lt;- sample(501:600, size = 4)
pred_list_all[[1]] %&gt;% filter(id %in% rand_id) %&gt;%
  mutate_at(vars(eta_i), function(x){exp(x)/(1+exp(x))}) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.2)+
  geom_line(aes(x=t, y=eta_i, col = &quot;True&quot;), show.legend = F)+
  facet_wrap(~id)+
  labs(title = &quot;Simulated data&quot;)+
  scale_x_continuous(breaks = seq(0, 1, by = 0.2))</code></pre>
<p><img src="manuscript_files/figure-html/fig_sim_data-1.png" width="672" /></p>
</div>
<div id="reference-method" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Reference method</h2>
<ul>
<li>GLMMadaptive</li>
<li>Here we can fit a model with random intercept and slope for time. It
is doable on 500 datasets, but obviously too simple for the data
generation scheme. We would expect it to perform terribly.</li>
</ul>
<p><span class="math display">\[g(E(Y_i(t))) =
\beta_0+\beta_1t+b_{i0}+b_{i1}t\]</span></p>
</div>
<div id="figure" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Figure</h2>
<pre class="r"><code># range(pred_list_all[[1]]$pred0.2, na.rm = T)
fig_fgfpca &lt;- pred_list_all[[1]] %&gt;%
  filter(id %in% rand_id) %&gt;%
  mutate_at(vars(eta_i, pred0.2, pred0.4, pred0.6, pred0.8), function(x){exp(x)/(1+exp(x))}) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.2)+
  geom_line(aes(x=t, y=eta_i, col = &quot;True&quot;))+
  geom_line(aes(x=t, y=pred0.2, col = &quot;0.2&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.4, col = &quot;0.4&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.6, col = &quot;0.6&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.8, col = &quot;0.8&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  facet_wrap(~id)+
  labs(title = &quot;fGFPCA&quot;, col = &quot;Maximum observation time&quot;)+
  scale_x_continuous(breaks = seq(0, 1, by = 0.2))+
  theme(axis.text = element_text(size = 5))

fig_adglmm &lt;- pred_list_ref[[1]] %&gt;%
  filter(id %in% rand_id) %&gt;%
  mutate_at(vars(eta_i, pred0.2, pred0.4, pred0.6, pred0.8), function(x){exp(x)/(1+exp(x))}) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.2)+
  geom_line(aes(x=t, y=eta_i, col = &quot;True&quot;))+
  geom_line(aes(x=t, y=pred0.2, col = &quot;0.2&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.4, col = &quot;0.4&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.6, col = &quot;0.6&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.8, col = &quot;0.8&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  facet_wrap(~id)+
  labs(title = &quot;GLMMadaptive&quot;, col = &quot;Maximum observation time&quot;)+
  scale_x_continuous(breaks = seq(0, 1, by = 0.2))+
  theme(axis.text = element_text(size = 5))</code></pre>
<pre class="r"><code>ggarrange(fig_fgfpca, fig_adglmm,
          nrow = 1, common.legend = T)</code></pre>
<p><img src="manuscript_files/figure-html/fig_sim-1.png" width="768" /></p>
</div>
<div id="ise" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> ISE</h2>
<pre class="r"><code>## ISE container 
ise_mat &lt;- ise_mat_ref &lt;- array(NA, 
                                dim = c(length(window)-2, length(window)-2, M))
# dims: prediction window, max obs time, simulation iter</code></pre>
<pre class="r"><code>## calculation
for(m in 1:M){
  this_df &lt;- pred_list_all[[m]]
  ise_tb &lt;- pred_list_all[[m]] %&gt;%
    mutate(err1 = (pred0.2-eta_i)^2,
           err2 = (pred0.4-eta_i)^2,
           err3 = (pred0.6-eta_i)^2,
           err4 = (pred0.8-eta_i)^2) %&gt;%
    select(id, t, starts_with(&quot;err&quot;)) %&gt;% 
    mutate(window = cut(t, breaks = window, include.lowest = T)) %&gt;% 
    group_by(window, id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;% 
    group_by(window) %&gt;% 
    summarize_at(vars(err1, err2, err3, err4), mean) %&gt;%
    filter(window != &quot;[0,0.2]&quot;) %&gt;% 
    select(starts_with(&quot;err&quot;))
  ise_mat[, ,m] &lt;- as.matrix(ise_tb)
  
  
}

mean_ise &lt;- apply(ise_mat, c(1, 2), mean)

# mean_ise &lt;- data.frame(mean_ise) %&gt;%
#   mutate(Window = c(&quot;(0.2, 0.4]&quot;, &quot;(0.4, 0.6]&quot;, &quot;(0.6, 0.8]&quot;, &quot;(0.8, 1.0]&quot;),
#          .before = 1)
colnames(mean_ise) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>## calculation
for(m in 1:M){
  this_df &lt;- pred_list_ref[[m]]
  ise_tb &lt;- pred_list_ref[[m]] %&gt;%
    mutate(err1 = (pred0.2-eta_i)^2,
           err2 = (pred0.4-eta_i)^2,
           err3 = (pred0.6-eta_i)^2,
           err4 = (pred0.8-eta_i)^2) %&gt;%
    select(id, t, starts_with(&quot;err&quot;)) %&gt;% 
    mutate(window = cut(t, breaks = window, include.lowest = T)) %&gt;% 
    group_by(window, id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;% 
    group_by(window) %&gt;% 
    summarize_at(vars(err1, err2, err3, err4), mean) %&gt;%
    filter(window != &quot;[0,0.2]&quot;) %&gt;% 
    select(starts_with(&quot;err&quot;))
  ise_mat_ref[, ,m] &lt;- as.matrix(ise_tb)
  
  
}

mean_ise_ref &lt;- apply(ise_mat_ref, c(1, 2), mean)
# mean_ise_ref &lt;- data.frame(mean_ise_ref) %&gt;% 
#   mutate(Window = c(&quot;(0.2, 0.4]&quot;, &quot;(0.4, 0.6]&quot;, &quot;(0.6, 0.8]&quot;, &quot;(0.8, 1.0]&quot;),
#          .before = 1)
colnames(mean_ise_ref) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>data.frame(Window = c(&quot;(0.2, 0.4]&quot;, &quot;(0.4, 0.6]&quot;, &quot;(0.6, 0.8]&quot;, &quot;(0.8, 1.0]&quot;),
           mean_ise, mean_ise_ref, check.names = F) %&gt;%
  kable(digits = 3, caption = &quot;Integrated squared error&quot;, booktabs=T) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot; &quot;=1, &quot;fGFPCA&quot; = 4, &quot;GLMMadaptive&quot; = 4)) %&gt;%
  add_header_above(c(&quot; &quot;= 1, &quot;Maximum observation time&quot; = 8))</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Integrated squared error
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="8">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Maximum observation time
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
fGFPCA
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
GLMMadaptive
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Window
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(0.2, 0.4]
</td>
<td style="text-align:right;">
146.407
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
387.708
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.4, 0.6]
</td>
<td style="text-align:right;">
183.967
</td>
<td style="text-align:right;">
74.977
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
291.579
</td>
<td style="text-align:right;">
269.799
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.6, 0.8]
</td>
<td style="text-align:right;">
218.265
</td>
<td style="text-align:right;">
49.275
</td>
<td style="text-align:right;">
15.776
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
315.778
</td>
<td style="text-align:right;">
282.736
</td>
<td style="text-align:right;">
278.242
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.8, 1.0]
</td>
<td style="text-align:right;">
108.918
</td>
<td style="text-align:right;">
77.981
</td>
<td style="text-align:right;">
17.747
</td>
<td style="text-align:right;">
12.005
</td>
<td style="text-align:right;">
563.011
</td>
<td style="text-align:right;">
477.485
</td>
<td style="text-align:right;">
597.746
</td>
<td style="text-align:right;">
600.34
</td>
</tr>
</tbody>
</table>
</div>
<div id="auc" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> AUC</h2>
<pre class="r"><code>## a function to calculate AUC
get_auc &lt;- function(y, pred){
  if(sum(is.na(y))&gt;0 | sum(is.na(pred))&gt;0){
    auc &lt;- NA
  }
  else{
    this_perf &lt;- performance(prediction(pred, y), measure = &quot;auc&quot;)
    auc &lt;- this_perf@y.values[[1]]
  }
  return(auc)
}</code></pre>
<pre class="r"><code>## auc container 
auc_mat &lt;- array(NA, dim = c(length(window)-2, length(window)-2, M))
auc_mat_ref &lt;- array(NA, dim = c(length(window)-2, length(window)-2, M))</code></pre>
<pre class="r"><code>for(m in 1:M){
  this_df &lt;- pred_list_all[[m]]
  auc_tb &lt;- this_df %&gt;% 
    mutate(window = cut(t, breaks = window, include.lowest = T)) %&gt;% 
    select(Y, starts_with(&quot;pred&quot;), window) %&gt;%
    group_by(window) %&gt;%
    summarise(auc1 = get_auc(Y, pred0.2),
              auc2 = get_auc(Y, pred0.4),
              auc3 = get_auc(Y, pred0.6),
              auc4 = get_auc(Y, pred0.8)) %&gt;%
    filter(window != &quot;[0,0.2]&quot;) %&gt;% 
    select(starts_with(&quot;auc&quot;))
  auc_mat[, ,m] &lt;- as.matrix(auc_tb)

}


mean_auc &lt;- apply(auc_mat, c(1, 2), mean)
# mean_auc &lt;- data.frame(mean_auc) %&gt;% 
#   mutate(Window = c(&quot;(0.2, 0.4]&quot;, &quot;(0.4, 0.6]&quot;, &quot;(0.6, 0.8]&quot;, &quot;(0.8, 1.0]&quot;),
#          .before = 1)
colnames(mean_auc) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>for(m in 1:M){
  this_df &lt;- pred_list_ref[[m]]
  auc_tb &lt;- this_df %&gt;% 
    mutate(window = cut(t, breaks = window, include.lowest = T)) %&gt;% 
    select(Y, starts_with(&quot;pred&quot;), window) %&gt;%
    group_by(window) %&gt;%
    summarise(auc1 = get_auc(Y, pred0.2),
              auc2 = get_auc(Y, pred0.4),
              auc3 = get_auc(Y, pred0.6),
              auc4 = get_auc(Y, pred0.8)) %&gt;%
    filter(window != &quot;[0,0.2]&quot;) %&gt;% 
    select(starts_with(&quot;auc&quot;))
  auc_mat_ref[, ,m] &lt;- as.matrix(auc_tb)

}


mean_auc_ref &lt;- apply(auc_mat_ref, c(1, 2), mean)
# mean_auc &lt;- data.frame(mean_auc) %&gt;% 
#   mutate(Window = c(&quot;(0.2, 0.4]&quot;, &quot;(0.4, 0.6]&quot;, &quot;(0.6, 0.8]&quot;, &quot;(0.8, 1.0]&quot;),
#          .before = 1)
colnames(mean_auc_ref) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>data.frame(Window = c(&quot;(0.2, 0.4]&quot;, &quot;(0.4, 0.6]&quot;, &quot;(0.6, 0.8]&quot;, &quot;(0.8, 1.0]&quot;),
           mean_auc, mean_auc_ref, check.names = F) %&gt;%
  kable(digits = 3, caption = &quot;Area under the ROC curve&quot;, booktabs = T) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot; &quot;=1, &quot;fGFPCA&quot; = 4, &quot;GLMMadaptive&quot; = 4)) %&gt;%
  add_header_above(c(&quot; &quot;= 1, &quot;Maximum observation time&quot; = 8))</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Area under the ROC curve
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="8">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Maximum observation time
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
fGFPCA
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
GLMMadaptive
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Window
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(0.2, 0.4]
</td>
<td style="text-align:right;">
0.748
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.591
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.4, 0.6]
</td>
<td style="text-align:right;">
0.664
</td>
<td style="text-align:right;">
0.734
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.524
</td>
<td style="text-align:right;">
0.596
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.6, 0.8]
</td>
<td style="text-align:right;">
0.715
</td>
<td style="text-align:right;">
0.790
</td>
<td style="text-align:right;">
0.803
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.669
</td>
<td style="text-align:right;">
0.694
</td>
<td style="text-align:right;">
0.687
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.8, 1.0]
</td>
<td style="text-align:right;">
0.740
</td>
<td style="text-align:right;">
0.755
</td>
<td style="text-align:right;">
0.781
</td>
<td style="text-align:right;">
0.784
</td>
<td style="text-align:right;">
0.514
</td>
<td style="text-align:right;">
0.556
</td>
<td style="text-align:right;">
0.526
</td>
<td style="text-align:right;">
0.564
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>data.frame(
  &quot;Method&quot; = c(&quot;fGFPCA&quot;, &quot;GLMMadaptive&quot;),
  &quot;Fit&quot; = c(mean(fit_time)/60, mean(fit_time_ref)),
           &quot;Prediction&quot;= c(mean(pred_time), mean(pred_time_ref)/60)) %&gt;%
  kable(digits = 3, caption = &quot;Computation time (minutes)&quot;, booktabs = T) %&gt;%
  kable_styling(full_width = F) </code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Computation time (minutes)
</caption>
<thead>
<tr>
<th style="text-align:left;">
Method
</th>
<th style="text-align:right;">
Fit
</th>
<th style="text-align:right;">
Prediction
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
fGFPCA
</td>
<td style="text-align:right;">
0.725
</td>
<td style="text-align:right;">
1.592
</td>
</tr>
<tr>
<td style="text-align:left;">
GLMMadaptive
</td>
<td style="text-align:right;">
2.287
</td>
<td style="text-align:right;">
0.017
</td>
</tr>
</tbody>
</table>
<p>I think we could say that while the total time spend on model fitting
+ prediction are similar between two methods, fGFPCA achieved much
better flexibility and much better predictive performance of prediction
under every scenario.</p>
</div>
</div>
<div id="small-scale-simulation" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Small-scale
simulation</h1>
<p>Here we would like to fit fGFPCA and GLMMadaptive on a dataset with
smaller sample size and/or smaller measurement density. For the
GLMMadaptive model, we would set it up with spline basis functions so
that its flexibility is comparable with fGFPCA model, such as:</p>
<p><span class="math display">\[g(E(Y_i(t))) =
\sum_{k=1}^4\zeta_{k}B_k(t)+\sum_{l=1}^4\xi_{il}\phi_l(t)\]</span></p>
<p>I have used 100 subjects for training and testing, and repeated 100
times. When fitting GLMMadpative, I reduce the number of measurements to
1/10 by taking one every 10 observations. The prediction is on the
original grid.</p>
<pre class="r"><code>load(here(&quot;Data/SubSimOutput_GLMMadaptive.RData&quot;))
load(here(&quot;Data/SubSimOutput_fGFPCA.RData&quot;))</code></pre>
<div id="figure-1" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Figure</h2>
<pre class="r"><code>rand_id2 &lt;- sample(unique(pred_subset_fGFPCA[[1]]$id), 4)

fig_fgfpca_subset &lt;- pred_subset_fGFPCA[[1]] %&gt;%
  filter(id %in% rand_id2) %&gt;%
  mutate_at(vars(eta_i, starts_with(&quot;pred&quot;)), function(x){exp(x)/(1+exp(x))}) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.2)+
  geom_line(aes(x=t, y=eta_i, col = &quot;True&quot;))+
  geom_line(aes(x=t, y=pred0.2, col = &quot;0.2&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.4, col = &quot;0.4&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.6, col = &quot;0.6&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.8, col = &quot;0.8&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  facet_wrap(~id)+
  labs(title = &quot;fGFPCA&quot;, col = &quot;Maximum observation time&quot;)+
  scale_x_continuous(breaks = seq(0, 1, by = 0.2))+
  theme(axis.text = element_text(size = 5))

fig_adglmm_subset &lt;- pred_subset_adglmm[[1]] %&gt;% 
  filter(id %in% rand_id2) %&gt;%
  mutate_at(vars(eta_i, starts_with(&quot;pred&quot;)), function(x){exp(x)/(1+exp(x))}) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.2)+
  geom_line(aes(x=t, y=eta_i, col = &quot;True&quot;))+
  geom_line(aes(x=t, y=pred0.2, col = &quot;0.2&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.4, col = &quot;0.4&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.6, col = &quot;0.6&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.8, col = &quot;0.8&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  facet_wrap(~id)+
  labs(title = &quot;GLMMadaptive&quot;, col = &quot;Maximum observation time&quot;)+
  scale_x_continuous(breaks = seq(0, 1, by = 0.2))+
  theme(axis.text = element_text(size = 5))</code></pre>
<pre class="r"><code>ggarrange(fig_fgfpca_subset, fig_adglmm_subset,
          nrow = 1, common.legend = T)</code></pre>
<p><img src="manuscript_files/figure-html/fit_sim_small-1.png" width="768" /></p>
</div>
<div id="ise-1" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> ISE</h2>
<pre class="r"><code># M2 &lt;- length(pred_subset_fGFPCA)
## ISE container 
ise_mat_subset &lt;- array(NA, dim = c(length(window)-2, length(window)-2, length(pred_subset_fGFPCA)))

pred_subset_adglmm &lt;- pred_subset_adglmm[num_probs==0]
ise_mat_subset_ref &lt;- array(NA, dim = c(length(window)-2, length(window)-2, length(pred_subset_adglmm)))</code></pre>
<pre class="r"><code>for(m in 1:length(pred_subset_fGFPCA)){
  this_df &lt;- pred_subset_fGFPCA[[m]]
  ise_tb_m &lt;- this_df %&gt;%
    mutate(err1 = (pred0.2-eta_i)^2,
           err2 = (pred0.4-eta_i)^2,
           err3 = (pred0.6-eta_i)^2,
           err4 = (pred0.8-eta_i)^2) %&gt;%
    select(id, t, starts_with(&quot;err&quot;)) %&gt;% 
    mutate(window = cut(t, breaks = window, include.lowest = T)) %&gt;% 
    group_by(window, id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;% 
    group_by(window) %&gt;% 
    summarize_at(vars(err1, err2, err3, err4), mean) %&gt;%
    filter(window != &quot;[0,0.2]&quot;) %&gt;% 
    select(starts_with(&quot;err&quot;)) %&gt;% as.matrix()
  ise_mat_subset[,,m] &lt;- ise_tb_m
}

ise_mat_subset &lt;- apply(ise_mat_subset, c(1, 2), mean)

colnames(ise_mat_subset) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>for(m in 1:length(pred_subset_adglmm)){
  this_df &lt;- pred_subset_adglmm[[m]]
  ise_tb_m &lt;- this_df %&gt;%
    mutate(err1 = (pred0.2-eta_i)^2,
           err2 = (pred0.4-eta_i)^2,
           err3 = (pred0.6-eta_i)^2,
           err4 = (pred0.8-eta_i)^2) %&gt;%
    select(id, t, starts_with(&quot;err&quot;)) %&gt;% 
    mutate(window = cut(t, breaks = window, include.lowest = T)) %&gt;% 
    group_by(window, id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;% 
    group_by(window) %&gt;% 
    summarize_at(vars(err1, err2, err3, err4), mean) %&gt;%
    filter(window != &quot;[0,0.2]&quot;) %&gt;% 
    select(starts_with(&quot;err&quot;)) %&gt;% as.matrix()
  ise_mat_subset_ref[,,m] &lt;- ise_tb_m
}

ise_mat_subset_ref &lt;- apply(ise_mat_subset_ref, c(1, 2), mean)


colnames(ise_mat_subset_ref) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>data.frame(Window = c(&quot;(0.2,0.4]&quot;, &quot;(0.4,0.6]&quot;, &quot;(0.6,0.8]&quot;, &quot;(0.8, 1.0]&quot;),
           ise_mat_subset, ise_mat_subset_ref, check.names = F) %&gt;%
  kable(digits = 3, caption = &quot;Integrated squared error&quot;, booktabs = T) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot; &quot;=1, &quot;fGFPCA&quot; = 4, &quot;GLMMadaptive&quot; = 4)) %&gt;%
  add_header_above(c(&quot; &quot;= 1, &quot;Observation track&quot; = 8))</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Integrated squared error
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="8">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Observation track
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
fGFPCA
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
GLMMadaptive
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Window
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(0.2,0.4]
</td>
<td style="text-align:right;">
150.641
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
374.836
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.4,0.6]
</td>
<td style="text-align:right;">
188.065
</td>
<td style="text-align:right;">
77.380
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
268.390
</td>
<td style="text-align:right;">
463.337
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.6,0.8]
</td>
<td style="text-align:right;">
224.001
</td>
<td style="text-align:right;">
51.533
</td>
<td style="text-align:right;">
16.879
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
319.731
</td>
<td style="text-align:right;">
287.001
</td>
<td style="text-align:right;">
233.510
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.8, 1.0]
</td>
<td style="text-align:right;">
112.163
</td>
<td style="text-align:right;">
81.368
</td>
<td style="text-align:right;">
19.592
</td>
<td style="text-align:right;">
13.399
</td>
<td style="text-align:right;">
228.335
</td>
<td style="text-align:right;">
469.769
</td>
<td style="text-align:right;">
331.509
</td>
<td style="text-align:right;">
131.993
</td>
</tr>
</tbody>
</table>
</div>
<div id="auc-1" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> AUC</h2>
<pre class="r"><code>## auc container 
auc_mat_subset &lt;- array(NA, dim = c(length(window)-2, length(window)-2, 
                                    length(pred_subset_fGFPCA)))
auc_mat_subset_ref &lt;- array(NA, dim = c(length(window)-2, length(window)-2, 
                                        length(pred_subset_adglmm)))</code></pre>
<pre class="r"><code>for(m in 1:length(pred_subset_fGFPCA)){
  this_df &lt;- pred_subset_fGFPCA[[m]]
  
  auc_tb_m &lt;- this_df %&gt;%
  mutate(window = cut(t, breaks = window, include.lowest = T)) %&gt;% 
  select(Y, starts_with(&quot;pred&quot;), window) %&gt;%
  group_by(window) %&gt;%
  summarise(auc1 = get_auc(Y, pred0.2),
            auc2 = get_auc(Y, pred0.4),
            auc3 = get_auc(Y, pred0.6),
            auc4 = get_auc(Y, pred0.8)) %&gt;%
  filter(window != &quot;[0,0.2]&quot;) %&gt;% 
  select(starts_with(&quot;auc&quot;)) %&gt;% as.matrix()
  
  auc_mat_subset[, , m] &lt;- auc_tb_m
  
}


auc_mat_subset &lt;- apply(auc_mat_subset, c(1,2), mean)
colnames(auc_mat_subset) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>for(m in 1:length(pred_subset_adglmm)){
  this_df &lt;- pred_subset_adglmm[[m]]
  
  auc_tb_m &lt;- this_df %&gt;%
  mutate(window = cut(t, breaks = window, include.lowest = T)) %&gt;% 
  select(Y, starts_with(&quot;pred&quot;), window) %&gt;%
  group_by(window) %&gt;%
  summarise(auc1 = get_auc(Y, pred0.2),
            auc2 = get_auc(Y, pred0.4),
            auc3 = get_auc(Y, pred0.6),
            auc4 = get_auc(Y, pred0.8)) %&gt;%
  filter(window != &quot;[0,0.2]&quot;) %&gt;% 
  select(starts_with(&quot;auc&quot;)) %&gt;% as.matrix()
  
  auc_mat_subset_ref[, , m] &lt;- auc_tb_m
  
}

auc_mat_subset_ref &lt;- apply(auc_mat_subset_ref, c(1,2), mean)
colnames(auc_mat_subset_ref) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>data.frame(Window = c(&quot;(0.2,0.4]&quot;, &quot;(0.4,0.6]&quot;, &quot;(0.6,0.8]&quot;, &quot;(0.8, 1.0]&quot;),
           auc_mat_subset, auc_mat_subset_ref, check.names = F) %&gt;%
  kable(digits = 3, caption = &quot;Area under the ROC curve&quot;, booktabs = T) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot; &quot;=1, &quot;fGFPCA&quot; = 4, &quot;GLMMadaptive&quot; = 4)) %&gt;%
  add_header_above(c(&quot; &quot;= 1, &quot;Observation track&quot; = 8))</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Area under the ROC curve
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="8">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Observation track
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
fGFPCA
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
GLMMadaptive
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Window
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(0.2,0.4]
</td>
<td style="text-align:right;">
0.746
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.672
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.4,0.6]
</td>
<td style="text-align:right;">
0.662
</td>
<td style="text-align:right;">
0.734
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.622
</td>
<td style="text-align:right;">
0.671
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.6,0.8]
</td>
<td style="text-align:right;">
0.710
</td>
<td style="text-align:right;">
0.787
</td>
<td style="text-align:right;">
0.801
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.689
</td>
<td style="text-align:right;">
0.698
</td>
<td style="text-align:right;">
0.731
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.8, 1.0]
</td>
<td style="text-align:right;">
0.740
</td>
<td style="text-align:right;">
0.754
</td>
<td style="text-align:right;">
0.781
</td>
<td style="text-align:right;">
0.784
</td>
<td style="text-align:right;">
0.681
</td>
<td style="text-align:right;">
0.629
</td>
<td style="text-align:right;">
0.679
</td>
<td style="text-align:right;">
0.743
</td>
</tr>
</tbody>
</table>
<p>Among 500 hundred iterations, 6 did not converge for the GLMMadaptive
model. No numeric issue for fGFPCA.</p>
<pre class="r"><code>data.frame(
  &quot;Method&quot; = c(&quot;fGFPCA&quot;, &quot;GLMMadaptive&quot;),
  &quot;Fit&quot; = c(mean(fit_time_subset_fGFPCA)/60, mean(fit_time_subset_adglmm, na.rm=T)),
           &quot;Prediction&quot;= c(mean(pred_time_subset_fGFPCA), mean(pred_time_subset_adglmm, na.rm=T)/60)) %&gt;%
  kable(digits = 3, caption = &quot;Computation time (minutes)&quot;, booktabs = T) %&gt;%
  kable_styling(full_width = F) </code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Computation time (minutes)
</caption>
<thead>
<tr>
<th style="text-align:left;">
Method
</th>
<th style="text-align:right;">
Fit
</th>
<th style="text-align:right;">
Prediction
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
fGFPCA
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
1.584
</td>
</tr>
<tr>
<td style="text-align:left;">
GLMMadaptive
</td>
<td style="text-align:right;">
5.455
</td>
<td style="text-align:right;">
0.024
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="nhanes-data-application" class="section level1" number="4">
<h1><span class="header-section-number">4</span> NHANES data
application</h1>
<p>We take 500 subjects for training, 500 for out-of-sample prediction.
When using the full sample The debiase step (mgcv::bam) in fGFPCA took a
really a long time, and GLMM adaptive only works for intercept-only
model. In the debias step, re-evaluated eigenvalues also lost their
decreasing nature.</p>
<p>In addition to reduce sample size, maybe we could just drop the
debias step and only interpolate the eigenfunctions?</p>
<pre class="r"><code>df_nhanes &lt;- read_rds(here(&quot;Data/nhanes_bi.rds&quot;))
load(here(&quot;Data/ApplOutput.RData&quot;))</code></pre>
<pre class="r"><code>df_nhanes %&gt;% select(SEQN, Z, sind) %&gt;% 
  filter(SEQN %in% unique(nhanes_pred_adglmm$id) | SEQN %in% unique(nhanes_pred_fgfpca$id)) %&gt;%
  mutate(Z = factor(Z, levels = 0:1, labels = c(&quot;Inactive&quot;, &quot;Active&quot;))) %&gt;%
  mutate(SEQN = factor(SEQN)) %&gt;%
  ggplot()+
  geom_tile(aes(x=sind, y = SEQN, fill = Z))+
  labs(x=&quot;Time&quot;, y=&quot;Subject&quot;, title = &quot;Overview of NHANES binary activity indicator&quot;)+
  theme(axis.text.y = element_blank())+
  scale_x_continuous(breaks = seq(0, 1440, by = 480),
                     labels = c(&quot;Midnight&quot;, &quot;8am&quot;, &quot;4pm&quot;, &quot;Midnight&quot;))</code></pre>
<p><img src="manuscript_files/figure-html/nhance_example-1.png" width="672" /></p>
<div id="auc-2" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> AUC</h2>
<pre class="r"><code>window3 &lt;- c(0, 480, 960, 1440)

auc_mat_nhanes &lt;- nhanes_pred_fgfpca %&gt;%
  mutate(window = cut(t, breaks = window3, include.lowest = T)) %&gt;% 
  select(Y, starts_with(&quot;pred&quot;), window) %&gt;%
  group_by(window) %&gt;%
  summarise(auc1 = get_auc(Y, pred480),
            auc2 = get_auc(Y, pred960)) %&gt;%
  filter(window != &quot;[0,480]&quot;) %&gt;% 
  select(starts_with(&quot;auc&quot;))

colnames(auc_mat_nhanes) &lt;- c(&quot;8am&quot;, &quot;4pm&quot;)</code></pre>
<pre class="r"><code>auc_mat_nhanes2 &lt;- nhanes_pred_adglmm %&gt;%
  mutate(window = cut(t, breaks = window3, include.lowest = T)) %&gt;% 
  select(Y, starts_with(&quot;pred&quot;), window) %&gt;%
  group_by(window) %&gt;%
  summarise(auc1 = get_auc(Y, pred480),
            auc2 = get_auc(Y, pred960)) %&gt;%
  filter(window != &quot;[0,480]&quot;) %&gt;% 
  select(starts_with(&quot;auc&quot;))

colnames(auc_mat_nhanes2) &lt;- c(&quot;8am&quot;, &quot;4pm&quot;)</code></pre>
<pre class="r"><code>data.frame(Window = c(&quot;8am-4pm&quot;, &quot;4am-midnight&quot;),
           auc_mat_nhanes, auc_mat_nhanes2, check.names = F) %&gt;%
  kable(digits = 3, caption = &quot;Area Under the ROC curve&quot;, booktabs = T) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot; &quot;=1, &quot;fGFPCA&quot; = 2, &quot;GLMMadaptive&quot; = 2)) %&gt;%
  add_header_above(c(&quot; &quot;= 1, &quot;Maximum observation time&quot; = 4))</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Area Under the ROC curve
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Maximum observation time
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
fGFPCA
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
GLMMadaptive
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Window
</th>
<th style="text-align:right;">
8am
</th>
<th style="text-align:right;">
4pm
</th>
<th style="text-align:right;">
8am
</th>
<th style="text-align:right;">
4pm
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
8am-4pm
</td>
<td style="text-align:right;">
0.587
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.628
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
4am-midnight
</td>
<td style="text-align:right;">
0.680
</td>
<td style="text-align:right;">
0.766
</td>
<td style="text-align:right;">
0.448
</td>
<td style="text-align:right;">
0.613
</td>
</tr>
</tbody>
</table>
</div>
<div id="figure-2" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Figure</h2>
<pre class="r"><code>rand_id3 &lt;- sample(unique(nhanes_pred_fgfpca$id), 4)

ggarrange(
  nhanes_pred_fgfpca %&gt;% 
    filter(id %in% rand_id3) %&gt;%
    mutate_at(vars(starts_with(&quot;pred&quot;)), function(x)exp(x)/(1+exp(x))) %&gt;% 
    ggplot()+
    geom_line(aes(x=t, y = pred480, col = &quot;8am&quot;), linetype = &quot;dashed&quot;, na.rm = T)+
    geom_line(aes(x=t, y = pred960, col = &quot;4pm&quot;),linetype = &quot;dashed&quot;, na.rm = T)+
    geom_point(aes(x=t, y = Y, col = &quot;Outcome&quot;), size = 0.2)+
    facet_wrap(~id)+
    labs(x = &quot;Time&quot;, y = &quot;fGFPCA&quot;)+
  scale_x_continuous(breaks = seq(0, 1440, by = 480), 
                     labels = c(&quot;Midnight&quot;, &quot;8am&quot;, &quot;4pm&quot;, &quot;Midnight&quot;))+
  theme(axis.text = element_text(size = 5)),
  
  nhanes_pred_adglmm %&gt;% 
    filter(id %in% rand_id3) %&gt;%
    mutate_at(vars(starts_with(&quot;pred&quot;)), function(x)exp(x)/(1+exp(x))) %&gt;% 
    ggplot()+
    geom_line(aes(x=t, y = pred480, col = &quot;8am&quot;), linetype = &quot;dashed&quot;, na.rm = T)+
    geom_line(aes(x=t, y = pred960, col = &quot;4pm&quot;),linetype = &quot;dashed&quot;, na.rm = T)+
    geom_point(aes(x=t, y = Y, col = &quot;Outcome&quot;), size = 0.2)+
    facet_wrap(~id)+
    labs(x = &quot;Time&quot;, y = &quot;GLMMadaptive&quot;)+
  scale_x_continuous(breaks = seq(0, 1440, by = 480), 
                     labels = c(&quot;Midnight&quot;, &quot;8am&quot;, &quot;4pm&quot;, &quot;Midnight&quot;))+
  theme(axis.text = element_text(size = 5)),
  nrow = 1, common.legend = T)</code></pre>
<p><img src="manuscript_files/figure-html/pred_nhanes-1.png" width="960" /></p>
</div>
</div>
<div id="the-second-reference-method" class="section level1" number="5">
<h1><span class="header-section-number">5</span> The second reference
method:</h1>
<pre class="r"><code>load(here(&quot;Data/sim_data.RData&quot;))
df_m &lt;- sim_data[[1]]</code></pre>
<p>We would like to use a second reference method for predictive
performance comparision. In this model, predictions on a specific
interval are all made using the last few observations in the observed
window. For example, if we are given observations on [0, 0.2] (j =
1â€¦200), we may use L observations taken right before t=0.2 (<span
class="math inline">\(t_j: j=200, ... 200-(L-1)\)</span>) as time-fixed
covariate to predict any future time.</p>
<p>Letâ€™s write out the model expression (with questionable notation). If
the observations if up to <span class="math inline">\(t_m\)</span>,
then:</p>
<p><span class="math display">\[\begin{aligned}
g(E[Y_i(t)]) &amp;= \beta_0(t) +\sum_{l=1}^L \beta_l (t)Y_i(t_l)\\
l &amp; = m,...m-(j-1)\\
t &amp;&gt; t_m
\end{aligned}\]</span></p>
<p>This is a simple function-on-scalar model with no random effect,
meaning all subject with the same last observed outcome would have the
same estimated/predicted latent track. This is clearly anti-intuitive.
But adding random effects would make out-of-sample prediction
impossible.</p>
<p>Under this framework, for each dataset we need to fit four models
(similar to the GLMMadaptive method):</p>
<ul>
<li>Given 0-0.2, predict 0.2-1</li>
<li>Given 0-0.4, predict 0.4-1</li>
<li>Given 0-0.6, predict 0.6-1</li>
<li>Given 0-0.8, predict 0.8-1</li>
</ul>
<p>Below are some single dataset examples.</p>
<div id="example-of-l-1-given-0-0.2-to-predict-0.2-1"
class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Example of L = 1,
given [0, 0.2] to predict (0.2, 1)</h2>
<p>First let try to make prediction on an interval with only one
historical observation (L = 1):</p>
<p><span class="math display">\[\begin{aligned}
g(E[Y_i(t)]) &amp;= \beta_0(t) +\beta_1(t) Y_i(t_{m})\\
t &amp;&gt; t_m
\end{aligned}\]</span></p>
<pre class="r"><code>L &lt;- 1 # number of observations to use as predictor

# prediction window 
windows &lt;- seq(0, 1, by = 0.2)
df_m$window &lt;- cut(df_m$t, breaks=windows, labels = 1:5,
                       include.lowest = T)

# split data
N_train &lt;- 500
N_test &lt;- 100
train_df &lt;- df_m %&gt;% filter(id %in% 1:N_train)
test_df &lt;- df_m %&gt;% filter(!id %in% 1:N_train)</code></pre>
<pre class="r fold-show"><code># format training data
## given [0, 0.2], predictor would be
y_obs_max &lt;- train_df %&gt;% filter(window==1) %&gt;% arrange(desc(t)) %&gt;%
  group_by(id) %&gt;%
  slice(L) %&gt;% select(id, Y) %&gt;% rename(yl = Y)
## to predict (0.2, 1), outcome:
df_pred_tr &lt;- train_df %&gt;% filter(window!=1) %&gt;%
  left_join(y_obs_max, by = &quot;id&quot;) %&gt;% 
  mutate_at(vars(Y, yl), as.factor)

# range(df_pred_tr$sind)

# model
t1 &lt;- Sys.time()
fit_gen_fosr &lt;- bam(Y ~ s(t, bs=&quot;cc&quot;, k=20) + 
                        s(t, bs=&quot;cc&quot;, k=20, by = yl),
                   family = binomial, data=df_pred_tr, 
                   method = &quot;fREML&quot;,
                   discrete = TRUE)
t2 &lt;- Sys.time()
t2-t1</code></pre>
<pre><code>## Time difference of 0.721633 secs</code></pre>
<pre class="r fold-show"><code>summary(fit_gen_fosr)</code></pre>
<pre><code>## 
## Family: binomial 
## Link function: logit 
## 
## Formula:
## Y ~ s(t, bs = &quot;cc&quot;, k = 20) + s(t, bs = &quot;cc&quot;, k = 20, by = yl)
## 
## Parametric coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -0.001258   0.003210  -0.392    0.695
## 
## Approximate significance of smooth terms:
##               edf Ref.df    Chi.sq  p-value    
## s(t)      0.06865     18 4.200e-02 1.63e-05 ***
## s(t):yl0 15.69535     18 6.850e+06  &lt; 2e-16 ***
## s(t):yl1 13.60727     18 3.671e+06  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.029   Deviance explained = 2.11%
## fREML = 6.3905e+05  Scale est. = 1         n = 400000</code></pre>
<pre class="r"><code># estimation on the training set
df_pred_tr$eta_est &lt;- predict(fit_gen_fosr, type = &quot;link&quot;)

df_pred_tr %&gt;%
  mutate_at(vars(eta_est, eta_i), function(x){exp(x)/(1+exp(x))}) %&gt;%
  mutate_at(vars(Y), function(x){as.numeric(as.character(x))}) %&gt;%
  filter(id %in% 1:4) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.5)+
  geom_line(aes(x=t, y=eta_est, col = &quot;estimate&quot;))+
  geom_line(aes(x=t, y=eta_i, col = &quot;ture&quot;))+
  facet_wrap(~id)+
  labs(title = &quot;In-sample estimation&quot;)</code></pre>
<p><img src="manuscript_files/figure-html/est_train-1.png" width="672" /></p>
<pre class="r"><code># format testing data
df_pred_te &lt;- test_df %&gt;% filter(window!=1) %&gt;%
  left_join(test_df %&gt;% 
              filter(window==1) %&gt;% arrange(desc(t)) %&gt;% group_by(id) %&gt;%
              slice(L) %&gt;% select(id, Y) %&gt;% rename(yl = Y),
            by = &quot;id&quot;) %&gt;% 
  mutate_at(vars(Y, yl), as.factor)

# predict using the FOSR model fit above
df_pred_te$eta_est &lt;- predict(fit_gen_fosr, newdata = df_pred_te, type = &quot;link&quot;)

df_pred_te %&gt;%
  mutate_at(vars(eta_est, eta_i), function(x){exp(x)/(1+exp(x))}) %&gt;%
  mutate_at(vars(Y), function(x){as.numeric(as.character(x))}) %&gt;%
  filter(id %in% rand_id) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.5)+
  geom_line(aes(x=t, y=eta_est, col = &quot;estimate&quot;))+
  geom_line(aes(x=t, y=eta_i, col = &quot;ture&quot;))+
  facet_wrap(~id)+
  labs(title = &quot;Out-of-sample prediction&quot;)</code></pre>
<p><img src="manuscript_files/figure-html/pred_test-1.png" width="672" /></p>
</div>
<div id="example-of-prediction-on-one-dataset-l-1"
class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Example of prediction
on one dataset (L = 1)</h2>
<pre class="r"><code># table(df_m$window)
train_df$window &lt;- as.numeric(as.character(train_df$window))
test_df$window &lt;- as.numeric(as.character(test_df$window))
test_df2 &lt;- test_df

t1 &lt;- Sys.time()
for(w in 1:4){
  # model fit
  # predictor (training set)
  y_obs_max &lt;- train_df %&gt;% filter(window==w) %&gt;% arrange(desc(t)) %&gt;%
    group_by(id) %&gt;%
    slice(L) %&gt;% select(id, Y) %&gt;% rename(yl = Y)
  # outcome (training set)
  df_pred_tr &lt;- train_df %&gt;% filter(window &gt; w) %&gt;%
    left_join(y_obs_max, by = &quot;id&quot;) %&gt;% 
    mutate_at(vars(Y, yl), as.factor)
  # model 
  fit_gen_fosr &lt;- bam(Y ~ s(t, bs=&quot;cc&quot;, k=20) + 
                        s(t, bs=&quot;cc&quot;, k=20, by = yl),
                   family = binomial, data=df_pred_tr, 
                   method = &quot;fREML&quot;,
                   discrete = TRUE)
  
  # prediction
  # predictor (testing set)
  y_obs_max_te &lt;- test_df %&gt;% 
                filter(window==w) %&gt;% arrange(desc(t)) %&gt;% group_by(id) %&gt;%
                slice(L) %&gt;% select(id, Y) %&gt;% rename(yl = Y)
  # outcome (testing set)
  df_pred_te &lt;- test_df %&gt;% filter(window &gt; w) %&gt;%
    left_join(y_obs_max_te, by = &quot;id&quot;) %&gt;% 
    mutate_at(vars(Y, yl), as.factor)

  # predict using the FOSR model fit above
  pred_name &lt;- paste0(&quot;pred_w&quot;, w)
  test_df[, pred_name] &lt;- NA
  test_df[test_df$window&gt;w, pred_name] &lt;- predict(fit_gen_fosr, newdata = df_pred_te, type = &quot;link&quot;)
}
t2 &lt;- Sys.time()
# t2-t1</code></pre>
<pre class="r"><code>test_df %&gt;%
  mutate_at(vars(eta_i, pred_w1, pred_w2, pred_w3, pred_w4), function(x){exp(x)/(1+exp(x))}) %&gt;%
  mutate_at(vars(Y), function(x){as.numeric(as.character(x))}) %&gt;%
  filter(id %in% rand_id) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.5)+
  geom_line(aes(x=t, y=pred_w1, col = &quot;Up to 0.1&quot;), na.rm=T)+
  geom_line(aes(x=t, y=pred_w2, col = &quot;Up to 0.2&quot;), na.rm=T)+
  geom_line(aes(x=t, y=pred_w3, col = &quot;Up to 0.3&quot;), na.rm=T)+
  geom_line(aes(x=t, y=pred_w4, col = &quot;Up to 0.4&quot;), na.rm=T)+
  geom_line(aes(x=t, y=eta_i, col = &quot;ture&quot;))+
  facet_wrap(~id)+
  labs(title = &quot;Out-of-sample prediction&quot;)</code></pre>
<p><img src="manuscript_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="example-of-prediction-on-one-dataset-l-5"
class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Example of prediction
on one dataset (L = 5)</h2>
<pre class="r"><code>t1 &lt;- Sys.time()
for(w in 1:4){
  # model fit
  # predictor (training set)
  y_obs_max &lt;- train_df %&gt;% filter(window==w) %&gt;% group_by(id) %&gt;%
    slice_max(t, n=5) %&gt;% select(id, Y, sind) %&gt;%
    mutate(name = sind-min(sind)+1) %&gt;%
    pivot_wider(id_cols = id, values_from = Y, names_from = &quot;name&quot;, names_prefix = &quot;yl&quot;)
  # outcome (training set)
  df_pred_tr &lt;- train_df %&gt;% filter(window &gt; w) %&gt;%
    left_join(y_obs_max, by = &quot;id&quot;) %&gt;% 
    mutate_at(vars(Y, starts_with(&quot;yl&quot;)), as.factor) 
  fit_gen_fosr &lt;- bam(Y ~ s(t, bs=&quot;cc&quot;, k=20) + 
                        s(t, bs=&quot;cc&quot;, k=20, by = yl5)+
                        s(t, bs=&quot;cc&quot;, k=20, by = yl4)+
                        s(t, bs=&quot;cc&quot;, k=20, by = yl3)+
                        s(t, bs=&quot;cc&quot;, k=20, by = yl2)+
                        s(t, bs=&quot;cc&quot;, k=20, by = yl1),
                   family = binomial, data=df_pred_tr, 
                   method = &quot;fREML&quot;,
                   discrete = TRUE)
  
  # prediction
  # predictor (testing set)
  y_obs_max_te &lt;- test_df2 %&gt;% filter(window==w) %&gt;% group_by(id) %&gt;%
    slice_max(t, n=5) %&gt;% select(id, Y, sind) %&gt;% 
    mutate(name = sind-min(sind)+1) %&gt;%
    pivot_wider(id_cols = id, values_from = Y, names_from = name, names_prefix = &quot;yl&quot;)
  # outcome (testing set)
  df_pred_te &lt;- test_df2 %&gt;% filter(window &gt; w) %&gt;%
    left_join(y_obs_max_te, by = &quot;id&quot;) %&gt;% 
    mutate_at(vars(Y, starts_with(&quot;yl&quot;)), as.factor)

  # predict using the FOSR model fit above
  pred_name &lt;- paste0(&quot;pred_w&quot;, w)
  test_df2[, pred_name] &lt;- NA
  test_df2[test_df2$window&gt;w, pred_name] &lt;- predict(fit_gen_fosr, newdata = df_pred_te, type = &quot;link&quot;)
}
t2 &lt;- Sys.time()
# t2-t1</code></pre>
<pre class="r"><code>test_df2 %&gt;%
  mutate_at(vars(eta_i, pred_w1, pred_w2, pred_w3, pred_w4), function(x){exp(x)/(1+exp(x))}) %&gt;%
  mutate_at(vars(Y), function(x){as.numeric(as.character(x))}) %&gt;%
  filter(id %in% rand_id) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.5)+
  geom_line(aes(x=t, y=pred_w1, col = &quot;Up to 0.1&quot;), na.rm=T)+
  geom_line(aes(x=t, y=pred_w2, col = &quot;Up to 0.2&quot;), na.rm=T)+
  geom_line(aes(x=t, y=pred_w3, col = &quot;Up to 0.3&quot;), na.rm=T)+
  geom_line(aes(x=t, y=pred_w4, col = &quot;Up to 0.4&quot;), na.rm=T)+
  geom_line(aes(x=t, y=eta_i, col = &quot;ture&quot;))+
  facet_wrap(~id)+
  labs(title = &quot;Out-of-sample prediction&quot;)</code></pre>
<p><img src="manuscript_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>This method is very, very fast, takes 10 seconds or so, much faster
than both fGFPCA and GLMMadaptive. The performance lies in between them
for most cases, sometimes worse than GLMMadaptive.</p>
<p>Do we really want to use the lag-1 model?</p>
<pre class="r"><code>tb_ies_l5 &lt;- test_df2 %&gt;%
    mutate(err1 = (pred_w1-eta_i)^2,
           err2 = (pred_w2-eta_i)^2,
           err3 = (pred_w3-eta_i)^2,
           err4 = (pred_w4-eta_i)^2) %&gt;%
    select(id, t, window, starts_with(&quot;err&quot;)) %&gt;% 
    group_by(window, id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;% 
    group_by(window) %&gt;% 
    summarize_at(vars(err1, err2, err3, err4), mean) %&gt;%
    filter(window != 1) %&gt;%
  select(starts_with(&quot;err&quot;))

tb_ies_l1 &lt;- test_df %&gt;%
    mutate(err1 = (pred_w1-eta_i)^2,
           err2 = (pred_w2-eta_i)^2,
           err3 = (pred_w3-eta_i)^2,
           err4 = (pred_w4-eta_i)^2) %&gt;%
    select(id, t, window, starts_with(&quot;err&quot;)) %&gt;% 
    group_by(window, id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;% 
    group_by(window) %&gt;% 
    summarize_at(vars(err1, err2, err3, err4), mean) %&gt;%
    filter(window != 1) %&gt;%
  select(starts_with(&quot;err&quot;))

colnames(tb_ies_l1) &lt;- colnames(tb_ies_l5) &lt;- c(&quot;0.2&quot;, &quot;0.4&quot;, &quot;0.6&quot;, &quot;0.8&quot;)</code></pre>
<pre class="r"><code>data.frame(Window = c(&quot;(0.2,0.4]&quot;, &quot;(0.4,0.6]&quot;, &quot;(0.6,0.8]&quot;, &quot;(0.8, 1.0]&quot;),
           tb_ies_l1, tb_ies_l5, check.names = F) %&gt;%
  kable(digits = 3, caption = &quot;Integrated squared error&quot;, booktabs = T) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot; &quot;=1, &quot;L = 1&quot; = 4, &quot;L = 5&quot; = 4)) %&gt;%
  add_header_above(c(&quot; &quot;= 1, &quot;Observation track&quot; = 8))</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Integrated squared error
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="8">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Observation track
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
L = 1
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
L = 5
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Window
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(0.2,0.4]
</td>
<td style="text-align:right;">
348.343
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
306.978
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.4,0.6]
</td>
<td style="text-align:right;">
285.238
</td>
<td style="text-align:right;">
252.385
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
274.415
</td>
<td style="text-align:right;">
213.787
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.6,0.8]
</td>
<td style="text-align:right;">
278.837
</td>
<td style="text-align:right;">
308.303
</td>
<td style="text-align:right;">
298.876
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
241.906
</td>
<td style="text-align:right;">
291.673
</td>
<td style="text-align:right;">
241.131
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.8, 1.0]
</td>
<td style="text-align:right;">
326.627
</td>
<td style="text-align:right;">
342.585
</td>
<td style="text-align:right;">
349.281
</td>
<td style="text-align:right;">
347.882
</td>
<td style="text-align:right;">
306.177
</td>
<td style="text-align:right;">
311.937
</td>
<td style="text-align:right;">
366.169
</td>
<td style="text-align:right;">
337.832
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="additional-figures" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Additional figures</h1>
<!-- ## fGFPCA algorithm demonstration -->
<!-- ```{r binning, eval=FALSE} -->
<!-- df_nhanes %>% select(SEQN, Z, sind) %>%  -->
<!--   filter(SEQN %in% rand_id3 & sind >= 650 & sind <= 750) %>%  -->
<!--   mutate(SEQN = as.factor(SEQN)) %>%  -->
<!--   ggplot()+ -->
<!--   geom_point(aes(x=sind, y = Z, col = SEQN), size = 0.5)+ -->
<!--   geom_vline(xintercept = seq(650, 750, by = 10), linetype="dashed")+ -->
<!--   scale_y_continuous(breaks = c(0, 1))+ -->
<!--   labs(x="Time", y="", title = "NHANES binary activity indicator") -->
<!-- ``` -->
<!-- ```{r,eval=FALSE} -->
<!-- df_fig <- df_nhanes %>% select(SEQN, Z, sind) %>%  -->
<!--   filter(SEQN %in% rand_id3 & sind >= 650 & sind <= 750) %>%  -->
<!--   mutate(bin = cut(sind, breaks = seq(650, 750, by = 10),  -->
<!--                    labels = seq(655, 745, by = 10), -->
<!--                    include.lowest = T))  -->
<!-- bin_mid <- seq(655, 745, by = 10) -->
<!-- for(i in bin_mid){ -->
<!--   df_bin_i <- df_fig %>% filter(bin==i)  -->
<!--   glm_i <- glmer(Z ~ 1 + (1|SEQN), data = df_bin_i, family = binomial, nAGQ=0) -->
<!--   eta_i <- predict(glm_i, type = "link") -->
<!--   df_fig$eta_hat[df_fig$bin==i] <- eta_i -->
<!-- } -->
<!-- df_fig %>%  -->
<!--   mutate(SEQN = as.factor(SEQN), -->
<!--          eta_hat = exp(eta_hat)/(1+exp(eta_hat)), -->
<!--          bin=as.numeric(as.character(bin))) %>%  -->
<!--   ggplot()+ -->
<!--   geom_point(aes(x=sind, y = Z, col = SEQN), size = 0.5)+ -->
<!--   geom_vline(xintercept = seq(650, 750, by = 10), linetype="dashed")+ -->
<!--   geom_point(aes(x=bin, y=eta_hat, col = SEQN))+ -->
<!--   geom_line(aes(x=bin, y=eta_hat, col = SEQN))+ -->
<!--   scale_y_continuous(breaks = c(0, 1))+ -->
<!--   labs(x="Time", y="", title = "NHANES binary activity indicator") -->
<!-- ``` -->
<!-- ## Example of continuous and binary NHANES -->
<!-- ```{r, eval=FALSE} -->
<!-- df_nhanes_cont <- readRDS(here("Data/NHANES_AC_processed.rds")) -->
<!-- p_cont <- df_nhanes_cont %>%  -->
<!--   filter(SEQN %in% sample(unique(df_nhanes_cont$SEQN), 4) & WEEKDAY==6) %>%  -->
<!--   select(starts_with("min"), SEQN) %>% -->
<!--   pivot_longer(1:1440, names_to = "Minute") %>%  -->
<!--   mutate(Minute = gsub("MIN", "", Minute)) %>% -->
<!--   mutate(Minute = as.numeric(Minute), -->
<!--          SEQN=as.factor(SEQN)) %>% -->
<!--   ggplot(aes(x=Minute, y=value, col=SEQN))+ -->
<!--   geom_point(size = 0.5, alpha=0.5)+ -->
<!--   geom_smooth(se=F, size = 0.5)+ -->
<!--   scale_x_continuous(breaks = seq(0, 1440, by = 480), -->
<!--                      labels = c("Midnight", "8am", "4pm", "Midnight"))+ -->
<!--   theme(axis.text = element_text(size = 5))+ -->
<!--   labs(y="", title = "NHANES Activitiy count (2003-2004)") -->
<!-- ``` -->
<!-- ```{r, eval=FALSE} -->
<!-- # a example of continuous and binary NHANES data -->
<!-- p_bi <- df_nhanes %>% select(SEQN, Z, sind) %>%  -->
<!--   filter(SEQN %in% rand_id3 & Z == 1) %>%  -->
<!--   mutate(SEQN = as.factor(SEQN)) %>%  -->
<!--   ggplot()+ -->
<!--   geom_point(aes(x=sind, y = SEQN), size = 0.5)+ -->
<!--   scale_x_continuous(breaks = seq(0, 1440, by = 480), -->
<!--                      labels = c("Midnight", "8am", "4pm", "Midnight"))+ -->
<!--   theme(axis.text = element_text(size = 5))+ -->
<!--   labs(x="Time", y="Subject", title = "NHANES binary activity indicator (2011-2014)") -->
<!-- ``` -->
<!-- ```{r data_exp, fig.height=4, fig.width=10, eval=FALSE} -->
<!-- ggarrange(p_cont, p_bi, nrow = 1) -->
<!-- ``` -->
<!-- ## Dynamic prediction example -->
<!-- ```{r dynpred_exp,  fig.height=4, fig.width=10, eval=FALSE} -->
<!-- ggarrange( -->
<!--   pred_list_all[[1]] %>%  -->
<!--     filter(id==501) %>% -->
<!--     mutate(eta_i = ifelse(t<=0.2, eta_i, NA)) %>% -->
<!--     ggplot()+ -->
<!--     geom_line(aes(x=t, y=eta_i, col = "Observed"), na.rm = T)+ -->
<!--     geom_line(aes(x=t, y=pred0.2, col = "Predicted"), na.rm = T,  -->
<!--               linetype = "dashed")+ -->
<!--     geom_vline(xintercept = 0.2, linetype = "dashed")+ -->
<!--     labs(x="Time", y="")+ -->
<!--     scale_x_continuous(breaks = seq(0, 1, by = 0.2))+ -->
<!--     theme(axis.text = element_text(size = 5))+ -->
<!--     ylim(-1.2, 1.7), -->
<!--  pred_list_all[[1]] %>%  -->
<!--     filter(id==501) %>% -->
<!--     mutate(eta_i = ifelse(t<=0.4, eta_i, NA)) %>% -->
<!--     ggplot()+ -->
<!--     geom_line(aes(x=t, y=eta_i, col = "Observed"), na.rm = T)+ -->
<!--     geom_line(aes(x=t, y=pred0.4, col = "Predicted"), na.rm = T,  -->
<!--               linetype = "dashed")+ -->
<!--     geom_vline(xintercept = 0.4, linetype = "dashed")+ -->
<!--     labs(x="Time", y="")+ -->
<!--     scale_x_continuous(breaks = seq(0, 1, by = 0.2))+ -->
<!--     theme(axis.text = element_text(size = 5))+ -->
<!--    ylim(-1.2, 1.7), -->
<!--  nrow = 1, common.legend = T -->
<!--   ) -->
<!-- ``` -->
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

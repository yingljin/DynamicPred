<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ying Jin" />

<meta name="date" content="2023-09-15" />

<title>Progress Report on One Simulated Dataset</title>

<script src="ProgressReportSim_files/header-attrs-2.21/header-attrs.js"></script>
<script src="ProgressReportSim_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="ProgressReportSim_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="ProgressReportSim_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="ProgressReportSim_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="ProgressReportSim_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="ProgressReportSim_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="ProgressReportSim_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="ProgressReportSim_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="ProgressReportSim_files/navigation-1.1/tabsets.js"></script>
<script src="ProgressReportSim_files/navigation-1.1/codefolding.js"></script>
<link href="ProgressReportSim_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="ProgressReportSim_files/highlightjs-9.12.0/highlight.js"></script>
<script src="ProgressReportSim_files/kePrint-0.0.1/kePrint.js"></script>
<link href="ProgressReportSim_files/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Progress Report on One Simulated
Dataset</h1>
<h4 class="author">Ying Jin</h4>
<h4 class="date">2023-09-15</h4>

</div>


<p>I am now on the way to add the debias step to the whole algorithm.
Just so that I have a set of “true parameters” for comparison, I am
gonna use the simulation dataset for this part.</p>
<div id="generation-mechanism" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Generation
mechanism</h1>
<ul>
<li>I am gonna generate only one dataset as an example</li>
<li>500 individuals each with 1000 measures</li>
</ul>
<p><span class="math display">\[\begin{aligned}
Y_i(t) &amp; \sim Bernoulli(\frac{exp(\eta_i(t))}{1+exp(\eta_i(t))}) \\
\eta_i(t) &amp;= f_0(t)+ \xi_{i1}\sqrt{2}sin(2\pi
t)+\xi_{i2}\sqrt{2}cos(2\pi t)+\xi_{i3}\sqrt{2}sin(4\pi
t)+\xi_{i4}\sqrt{2}cos(4\pi t)
\end{aligned}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(t\)</span> is equal-spaced on <span
class="math inline">\([0, 1]\)</span></li>
<li><span class="math inline">\(f_0(t)=0\)</span></li>
<li><span class="math inline">\(\xi_k \sim N(0, \lambda_k)\)</span>, and
<span class="math inline">\(\lambda_k = 1, 0.5, 0.25, 0.125\)</span> for
k = 1, 2, 3, 4 respectively.</li>
<li>In fact, since there is a constant factor <span
class="math inline">\(\sqrt{2}\)</span> before each eigenfunction so
that they are orthogonal</li>
</ul>
<pre class="r show"><code>N &lt;- 500 # sample size
J &lt;- 1000 # number of observation points

t = seq(0,1,len=J) # observations points

# mean function
f_0 &lt;- function(s) 0 

#eigenfunctions 
K &lt;- 4 # number of eigenfunctions
phi &lt;- sqrt(2)*cbind(sin(2*pi*t),cos(2*pi*t),
                     sin(4*pi*t),cos(4*pi*t))

# eigenvalues
lambda = 0.5^(0:(K-1)) </code></pre>
<pre class="r"><code># generated training data 
## score
xi &lt;- matrix(rnorm(N*K),N,K)
xi &lt;- xi %*% diag(sqrt(lambda))
  
# subject-specific random effect
b_i &lt;- xi %*% t(phi); # of size N by J
  
# latent gaussian function
eta_i &lt;- t(vapply(1:N, function(x){
    f_0(t) + b_i[x,]
  }, numeric(J)))
  
# outcome binary function
Y_i &lt;- matrix(rbinom(N*J, size=1, prob=plogis(eta_i)), 
                N, J, byrow=FALSE)
  
# format into dataframe
# id = subject identifier (factor variable)
# sind = numeric value corresponding to the observed functional domain
# Y = functional response (binary)
# sind_inx = numeric value associated with order of &quot;sind&quot;
#            this is not necessary, but may be of convenience when you implement the method
train_df &lt;- data.frame(id = factor(rep(1:N, each=J)),
                 t = rep(t, N), 
                 Y = as.vector(t(Y_i)),
                 eta_i = as.vector(t(eta_i)),
                 sind = rep(1:J, N))

# visualization
rand_id &lt;- sample(N, size = 4)
train_df %&gt;% filter(id %in% rand_id) %&gt;% 
  ggplot()+
  geom_point(aes(x=sind, y=Y), size = 0.5)+
  geom_line(aes(x=sind, y=plogis(eta_i)), col = &quot;red&quot;)+
  #geom_line(aes(x=sind_inx, y=eta_i), col = &quot;blue&quot;)+
  facet_wrap(~id)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
</div>
<div id="fgfpca-model-fitting" class="section level1" number="2">
<h1><span class="header-section-number">2</span> fGFPCA model
fitting</h1>
<ul>
<li>Training sample: N=500</li>
</ul>
<div id="bin-data" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Bin data</h2>
<ul>
<li>Bin every 10 consecutive observations</li>
</ul>
<pre class="r"><code># bin data
bin_w &lt;- 10 # bin width
n_bin &lt;- J/bin_w # number of bins
brks &lt;- seq(0, J, by = bin_w) # cutoff points
mid &lt;- (brks+bin_w/2)[1:n_bin] # mid points

train_df$bin &lt;- cut(train_df$sind, breaks = brks, include.lowest = T, labels = mid)
train_df$bin &lt;- as.numeric(as.character(train_df$bin))
# unique(df$bin)

train_df %&gt;% 
  filter(id %in% rand_id) %&gt;%
  group_by(id, bin) %&gt;%
  summarise(num = sum(Y)) %&gt;%
  ggplot()+
  geom_point(aes(x=bin, y=num), size = 0.5)+
  facet_wrap(~id)+
  labs(x=&quot;Time&quot;, y = &quot;Activity&quot;, title = &quot;Number of active nimutes within each bin&quot;)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="local-glmm" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Local GLMM</h2>
<ul>
<li>Used glmer with PIRLS (nAGQ=0) for local GLMMs step</li>
<li>Fit on the training set (N=500)</li>
<li>Use original time index ([0, 1]) as independent variable</li>
</ul>
<pre class="r"><code># fit model on the training set
train_bin_lst &lt;- split(train_df, f = train_df$bin)
# length(train_bin_lst)
# lapply(train_bin_lst, dim)

# local GLMM and estimate latent function
# use PIRLS (nAGQ=0) to avoid near-unidentifiability issues 
t1=Sys.time()
df_est_latent &lt;- lapply(train_bin_lst, function(x){pred_latent(x, n_node = 0)}) 
t2= Sys.time()
t_local_glmm &lt;- t2-t1 # less than 5 seconds</code></pre>
<pre class="r"><code>df_est_latent &lt;- bind_rows(df_est_latent) 
# head(df_est_latent)

# example estimated latent function
train_id &lt;- unique(train_df$id)
rand_id &lt;- sample(train_id, 4)

df_est_latent %&gt;% 
  filter(id %in% rand_id) %&gt;%
  mutate(eta_hat = exp(eta_hat)/(1+exp(eta_hat))) %&gt;%
  mutate(eta_i = exp(eta_i)/(1+exp(eta_i))) %&gt;%
  ggplot()+
  geom_line(aes(x=t, y=eta_hat, group = id, col = &quot;estimated&quot;))+
  geom_line(aes(x=t, y=eta_i, group = id, col = &quot;true&quot;))+
  geom_point(aes(x=t, y = Y, group = id), size = 0.5)+
  facet_wrap(~id, scales = &quot;free&quot;)+
  labs(x = &quot;Time&quot;, y = &quot;Estimated latent function (probablity scale)&quot;)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="fpca" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> FPCA</h2>
<pre class="r"><code>uni_eta_hat &lt;- df_est_latent %&gt;% filter(bin==sind)
mid_t &lt;- df_est_latent$t[df_est_latent$bin==df_est_latent$sind]
mid_t &lt;- unique(mid_t) # the time points correspoinding to bin midpoints

mat_est_unique &lt;- matrix(uni_eta_hat$eta_hat,
                         nrow=length(train_id), 
                         ncol=n_bin, byrow = F) 
# row index subject, column binned time
# dim(mat_est_unique)

t1 &lt;- Sys.time()
fpca_mod &lt;- fpca.face(mat_est_unique, argvals = mid_t, var=T)
t2 &lt;- Sys.time()
t_fpca &lt;- t2-t1 # less than one second</code></pre>
<ul>
<li>Estimated mean</li>
</ul>
<pre class="r"><code>plot(mid_t, fpca_mod$mu, type = &quot;l&quot;, xlab = &quot;bin&quot;, ylab = &quot;Mean&quot;)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<ul>
<li>Estimated eigenfunctions</li>
</ul>
<pre class="r"><code>par(mfrow=c(2,2))

plot(mid_t, fpca_mod$efunctions[, 1], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC1&quot;)
plot(mid_t, fpca_mod$efunctions[, 2], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC2&quot;)
plot(mid_t, fpca_mod$efunctions[, 3], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC3&quot;)
plot(mid_t, fpca_mod$efunctions[, 4], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC4&quot;)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-7-1.png" width="768" /></p>
<ul>
<li>Correlation matrix</li>
</ul>
<pre class="r"><code># plot correlation matrix
heatmap(cov2cor(fpca_mod$VarMats[[1]]), Rowv = NA, Colv = NA, main = &quot;Correlation&quot;)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<ul>
<li>Estimated eigenvalues</li>
</ul>
<pre class="r fold-show"><code># estimated eigenvalues from FPCA (biased)
fpca_mod$evalues[1:4]</code></pre>
<pre><code>## [1] 50.086753 23.167732 11.406167  6.059415</code></pre>
</div>
<div id="debias-step-4" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Debias (step 4)</h2>
<p>According to the fGFPCA paper, in this step we do two things:</p>
<ol style="list-style-type: decimal">
<li>Project the eigenfunctions with B-spline basis back to the original
grid</li>
<li>Debias the eigenvalues with GLMM (mgcv::bam, mgcm::gamm or
gamm4:gamm) to be used for Laplace approximation</li>
</ol>
<div id="porjection-with-b-spline-basis" class="section level3"
number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> Porjection with
B-spline basis</h3>
<!-- https://bookdown.org/ssjackson300/Machine-Learning-Lecture-Notes/splines.html -->
<ul>
<li>Use fastGFPCA::reeval_efunctions. Cannot install the package so used
the source code directly</li>
<li>I would like to adjust use time points on the [0, 1] scale as
evaluation points</li>
<li>Also, take number of knots and order from the FPCA model in step 3
(knots = 35, p = 3)</li>
</ul>
<pre class="r fold-show"><code># order of b splines
p &lt;- 3 

# knots
knots &lt;- 35
knots_values &lt;- seq(-p, knots + p, length = knots + 1 + 2 *p)/knots
knots_values &lt;- knots_values * (max(mid_t) - min(mid_t)) + min(mid_t)

# evaluate B-splines on binned grid
B &lt;- spline.des(knots = knots_values, x = mid_t, ord = p + 1,
                            outer.ok = TRUE)$design
# evaluate B-splines on original grid
Bnew &lt;- spline.des(knots = knots_values, x = unique(train_df$t), ord = p + 1,
                  outer.ok = TRUE)$design

# project binned eigenfunctions onto the original grid
efunctions_new &lt;- matrix(NA, J, K)
for(k in 1:K){
    lm_mod &lt;- lm(fpca_mod$efunctions[,k] ~ B-1)
    efunctions_new[,k] &lt;- Bnew %*% coef(lm_mod)
}

# project mean functions 
lm_mod &lt;- lm(fpca_mod$mu ~ B-1)
mu_new &lt;- Bnew %*% coef(lm_mod)</code></pre>
<pre class="r"><code># visualization
par(mfrow=c(2,2))

plot(mid_t, fpca_mod$efunctions[, 1], xlab=&quot;bin&quot;, ylab=&quot;PC1&quot;, pch=20, cex = 0.5)
lines(t, efunctions_new[, 1], col=&quot;blue&quot;)

plot(mid_t, fpca_mod$efunctions[, 2], xlab=&quot;bin&quot;, ylab=&quot;PC2&quot;, pch=20, cex = 0.5)
lines(t, efunctions_new[, 2], col=&quot;blue&quot;)

plot(mid_t, fpca_mod$efunctions[, 3], xlab=&quot;bin&quot;, ylab=&quot;PC3&quot;, pch=20, cex = 0.5)
lines(t, efunctions_new[, 3], col=&quot;blue&quot;)

plot(mid_t, fpca_mod$efunctions[, 4], xlab=&quot;bin&quot;, ylab=&quot;PC4&quot;, pch=20, cex = 0.5)
lines(t, efunctions_new[, 4], col=&quot;blue&quot;)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-11-1.png" width="768" /></p>
<ul>
<li>The projection seems to work very well!</li>
</ul>
</div>
<div id="debias-with-eigenvalues" class="section level3" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Debias with
eigenvalues</h3>
<ul>
<li>The bias was caused by the misspecification of latent process
(assume constant effect over smooth function).</li>
<li>What needs re-evaluation are eigenvalues (variance estimates). They
will be used in Laplace Approximation for out-of-sample prediction.</li>
<li>We do not need to debias individual scores because the scores for
training sample will not be used for out-of-sample prediction. And
out-of-sample scores are not estimated by FPCA but Laplace
approximation.</li>
<li>I will use the projected eigenfunctions from above.</li>
<li>I am using mgcv::bam and setting method = “fREML” and discrete =
TRUE to speed up computation</li>
</ul>
<pre class="r"><code># dim(fpca_mod$efunctions)
df_phi &lt;- data.frame(t = t, efunctions_new)
colnames(df_phi) &lt;- c(&quot;t&quot;, paste0(&quot;phi&quot;, 1:4))

# train_df$bin &lt;- as.numeric(as.character(train_df$bin))
train_df &lt;- train_df %&gt;% left_join(df_phi, by = &quot;t&quot;)
train_df$id &lt;- as.factor(train_df$id)</code></pre>
<pre class="r fold-show"><code># usethis::edit_r_environ()
t1 &lt;- Sys.time()
debias_glmm &lt;- bam(Y ~ s(t, bs=&quot;cr&quot;, k=10)+
                     s(id, by=phi1, bs=&quot;re&quot;)+
                     s(id, by=phi2, bs=&quot;re&quot;)+
                     s(id, by=phi3, bs=&quot;re&quot;)+
                     s(id, by=phi4, bs=&quot;re&quot;), 
                   family = binomial, data=train_df, 
                   method = &quot;fREML&quot;,
                   discrete = TRUE)
t2 &lt;- Sys.time()
t_debias &lt;- t2-t1 # less than 45 seconds</code></pre>
<p>And now I try to extract the variance of scores (debiased
eigenvalues), using the conclusion that connects smoothing parameters to
variance</p>
<p><span
class="math display">\[\hat{p}_k=1/\hat{\lambda}_k^2\]</span></p>
<pre class="r fold-show"><code># transformed smoothing parameters
new_lambda &lt;- 1/debias_glmm$sp[2:5]
new_lambda</code></pre>
<pre><code>## s(id):phi1 s(id):phi2 s(id):phi3 s(id):phi4 
##   95.40025   47.94811   25.76315   13.18696</code></pre>
<pre class="r fold-show"><code># new_lambda/lambda
# new_lambda/fpca_mod$evalues[1:4]</code></pre>
<p>This eigenvalues, as well as the eigenfunctions, are actually not on
the same scale of true values. By looking into the fpca.face source
code, eigenfunctions are scaled by the square root of the number of
total observations points. Since our model was fitted on the binnd grid,
the actual eigenvaleus and eigenfunctions would be:</p>
[
<span class="math display">\[\begin{aligned}
\phi_k(t) &amp; = \sqrt{n_{bin}}\hat{\phi}_k(t)  \\
\lambda_k &amp; = \hat{\lambda}_k/n_{bin}

\end{aligned}\]</span>
<p>]</p>
<p>Let’s rescale these quatities as below</p>
<ul>
<li>Re-scaled eigenvalues</li>
</ul>
<pre class="r"><code>new_lambda/n_bin</code></pre>
<pre><code>## s(id):phi1 s(id):phi2 s(id):phi3 s(id):phi4 
##  0.9540025  0.4794811  0.2576315  0.1318696</code></pre>
<ul>
<li>Re-scaled eigenfunctions</li>
</ul>
<pre class="r"><code>par(mfrow=c(2,2))

plot(mid_t, sqrt(n_bin)*fpca_mod$efunctions[, 1], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC1&quot;)
plot(mid_t, sqrt(n_bin)*fpca_mod$efunctions[, 2], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC2&quot;)
plot(mid_t, sqrt(n_bin)*fpca_mod$efunctions[, 3], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC3&quot;)
plot(mid_t, sqrt(n_bin)*fpca_mod$efunctions[, 4], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC4&quot;)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-16-1.png" width="768" />
- Both much closer to their true values</p>
</div>
</div>
</div>
<div id="out-of-sample-prediction-with-laplace-approximation"
class="section level1" number="3">
<h1><span class="header-section-number">3</span> Out-of-sample
prediction with Laplace approximation</h1>
<p>I will now estimate individual score of test sample using Laplace
Approximation, and calculated the predicted track.</p>
<ul>
<li>Generate additional 200 subjects for out-of-sample performance
evaluation</li>
<li>Maximum observations time: 0.2, 0.4, 0.6, 0.8</li>
<li>Prediction window: 0.2-0.4, 0.4-0.6, 0.6-0.8, 0.8-1.0</li>
</ul>
<div id="generate-test-data" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Generate test
data</h2>
<pre class="r"><code># generated testing data 
N_test &lt;- 200
b_test &lt;- matrix(rnorm(N_test*K), N_test, K) %*% diag(sqrt(lambda)) %*% t(phi) # of size N by J
# dim(b_test)
  
# latent gaussian function
eta_test &lt;- t(vapply(1:N_test, function(x){
    f_0(x) + b_i[x,]
  }, numeric(J)))

# outcome binary function
Y_test &lt;- matrix(rbinom(N_test*J, size=1, prob=plogis(eta_test)), 
                N_test, J, byrow=FALSE)
  
# format into dataframe
test_df &lt;- data.frame(id = factor(rep(1:N_test, each=J)),
                 t = rep(t, N_test), 
                 Y = as.vector(t(Y_test)),
                 eta_i = as.vector(t(eta_test)),
                 sind = rep(1:J, N_test))
# bin
test_df$bin &lt;- cut(test_df$sind, breaks = brks, include.lowest = T, labels = mid)
test_df$bin &lt;- as.numeric(as.character(test_df$bin))
test_df$id &lt;- as.factor(test_df$id)
test_id &lt;- unique(test_df$id)</code></pre>
</div>
<div id="laplace-approximation" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Laplace
approximation</h2>
<pre class="r"><code># the model
## now, with expanded mean and eigenfuncitons, a Bernoulli distribution at each time point
Model &lt;- function(parm, Data){
  xi &lt;- parm[Data$pos.xi]
  
  # log-prior
  xi.prior &lt;- dmvnorm(xi, mean = rep(0, Data$K), sigma=Data$tao, log = TRUE)
  
  # log-posterior likelihood
  eta &lt;- Data$f0+Data$X %*% xi
  p &lt;- exp(eta)/(1+exp(eta))
  LL &lt;- sum(dbern(x=Data$y, prob=p, log = TRUE)) # log likelihood of Y|xi
  LP &lt;- LL+sum(xi.prior) # joint log likelihood of (Y, xi)
  
  # output
  Modelout &lt;- list(LP=LP, Dev=-2*LL, Monitor=LL,
                   yhat=Data$y, parm=parm)
  return(Modelout)
}</code></pre>
<pre class="r"><code># parameter names
name_lst &lt;- as.list(rep(0, K))
names(name_lst) &lt;- paste(&quot;xi&quot;, 1:K, sep = &quot;&quot;)
parm.names &lt;- as.parm.names(name_lst)
pos.xi &lt;- grep(&quot;xi&quot;, parm.names)
PGF &lt;- function(Data) {
  xi &lt;- rnorm(Data$K)
  return(xi)
}
mon.names &lt;- &quot;LP&quot;</code></pre>
<pre class="r"><code># approximation process
# container
pred_list &lt;- list()
# score &lt;- array(NA, dim=c(length(test_id), K, 4))
# dimensions: subject, eigenfunction, maximum observation time

# prediction for a single subject
t1 &lt;- Sys.time()
# per subject
for(i in seq_along(test_id)){
  df_i &lt;- test_df %&gt;% filter(id==test_id[i])
  
  # per max obs time
  for(tmax in c(0.2, 0.4, 0.6, 0.8)){
    df_it &lt;- df_i %&gt;% filter(t &lt;= tmax)
    max_rid &lt;- nrow(df_it)
  
    # into a list
    MyData &lt;- list(K=K, PGF=PGF, 
                   X=efunctions_new[1: max_rid, ], 
                   mon.names=mon.names,
                   parm.names=parm.names, 
                   pos.xi=pos.xi, 
                   y=df_it$Y, 
                   tao=diag(new_lambda), f0=mu_new[1:max_rid, ])
    
    
    # fit laplace approximation
    Fit &lt;- LaplaceApproximation(Model, parm = rep(0, K), Data=MyData, Method = &quot;BFGS&quot;)
    # Fit &lt;- LaplacesDemon(Model, Data=MyData, Initial.Values = parm = rep(0, K),  Method = &quot;BFGS&quot;)
    score &lt;- Fit$Summary1[, &quot;Mode&quot;]
    
    # prediction
    eta_pred_out &lt;- mu_new+efunctions_new%*%score
    df_i[ , paste0(&quot;pred&quot;, tmax)] &lt;- eta_pred_out[,1]
  }
  
  # df_i$pred0.2[df_i$t&lt;=0.2] &lt;- NA
  # df_i$pred0.4[df_i$t&lt;=0.4] &lt;- NA
  # df_i$pred0.6[df_i$t&lt;=0.6] &lt;- NA
  # df_i$pred0.8[df_i$t&lt;=0.8] &lt;- NA
  
  pred_list[[i]] &lt;- df_i
}
t2 &lt;- Sys.time()
t_pred &lt;- t2-t1 # About 3.5 minutes</code></pre>
<pre class="r"><code>df_pred &lt;- bind_rows(pred_list)

df_pred$pred0.2[df_pred$t&lt;=0.2] &lt;- NA
df_pred$pred0.4[df_pred$t&lt;=0.4] &lt;- NA
df_pred$pred0.6[df_pred$t&lt;=0.6] &lt;- NA
df_pred$pred0.8[df_pred$t&lt;=0.8] &lt;- NA

rand_test_id &lt;- sample(test_id, 4)

p1&lt;-df_pred %&gt;%
  filter(id %in% rand_test_id) %&gt;%
  mutate_at(vars(eta_i, pred0.2, pred0.4, pred0.6, pred0.8), function(x){exp(x)/(1+exp(x))}) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.2)+
  geom_line(aes(x=t, y=eta_i, col = &quot;True&quot;))+
  geom_line(aes(x=t, y=pred0.2, col = &quot;0.2&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.4, col = &quot;0.4&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.6, col = &quot;0.6&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.8, col = &quot;0.8&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  facet_wrap(~id)+
  labs(title = &quot;Unscaled, debiased eigenvalues&quot;)</code></pre>
<div id="compared-to-biased-eigenvalues" class="section level3"
number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Compared to biased
eigenvalues</h3>
<pre class="r"><code>## With eigenvalues from FPCA
# container
pred_list2 &lt;- list()

# per subject
for(i in seq_along(test_id)){
  df_i &lt;- test_df %&gt;% filter(id==test_id[i])
  
  # per max obs time
  for(tmax in c(0.2, 0.4, 0.6, 0.8)){
    df_it &lt;- df_i %&gt;% filter(t &lt;= tmax)
    max_rid &lt;- nrow(df_it)
  
    # into a list
    MyData &lt;- list(K=K, PGF=PGF, 
                   X=efunctions_new[1: max_rid, ], 
                   mon.names=mon.names,
                   parm.names=parm.names, 
                   pos.xi=pos.xi, 
                   y=df_it$Y, 
                   tao=diag(fpca_mod$evalues[1:K]), f0=mu_new[1:max_rid, ])
    
    
    # fit laplace approximation
    Fit &lt;- LaplaceApproximation(Model, parm = rep(0, K), Data=MyData, Method = &quot;BFGS&quot;)
    # Fit &lt;- LaplacesDemon(Model, Data=MyData, Initial.Values = parm = rep(0, K),  Method = &quot;BFGS&quot;)
    score &lt;- Fit$Summary1[, &quot;Mode&quot;]
    
    # prediction
    eta_pred_out &lt;- mu_new+efunctions_new%*%score
    df_i[ , paste0(&quot;pred&quot;, tmax)] &lt;- eta_pred_out[,1]
  }
  
  # df_i$pred0.2[df_i$t&lt;=0.2] &lt;- NA
  # df_i$pred0.4[df_i$t&lt;=0.4] &lt;- NA
  # df_i$pred0.6[df_i$t&lt;=0.6] &lt;- NA
  # df_i$pred0.8[df_i$t&lt;=0.8] &lt;- NA
  
  pred_list2[[i]] &lt;- df_i
}</code></pre>
<pre class="r"><code>df_pred2 &lt;- bind_rows(pred_list2)

df_pred2$pred0.2[df_pred2$t&lt;=0.2] &lt;- NA
df_pred2$pred0.4[df_pred2$t&lt;=0.4] &lt;- NA
df_pred2$pred0.6[df_pred2$t&lt;=0.6] &lt;- NA
df_pred2$pred0.8[df_pred2$t&lt;=0.8] &lt;- NA
# overview of predicted track
p2&lt;-df_pred2 %&gt;%
  filter(id %in% rand_test_id) %&gt;%
  mutate_at(vars(eta_i, pred0.2, pred0.4, pred0.6, pred0.8), function(x){exp(x)/(1+exp(x))}) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.2)+
  geom_line(aes(x=t, y=eta_i, col = &quot;True&quot;))+
  geom_line(aes(x=t, y=pred0.2, col = &quot;0.2&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.4, col = &quot;0.4&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.6, col = &quot;0.6&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.8, col = &quot;0.8&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  facet_wrap(~id)+
  labs(title = &quot;Unscaled, biased eigenvalues&quot;)</code></pre>
</div>
<div id="scaled-eigenfunctions-and-eigenvalues" class="section level3"
number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Scaled
eigenfunctions and eigenvalues</h3>
<ul>
<li>No need to scale mean functions</li>
</ul>
<pre class="r"><code>## With debiased eigenvalues, also scale eigenvaleus and eigenfuncitons
# container
pred_list3 &lt;- list()
efunctions_scaled &lt;- efunctions_new*sqrt(n_bin)
evalues_scaled &lt;- new_lambda/n_bin

# per subject
for(i in seq_along(test_id)){
  df_i &lt;- test_df %&gt;% filter(id==test_id[i])
  
  # per max obs time
  for(tmax in c(0.2, 0.4, 0.6, 0.8)){
    df_it &lt;- df_i %&gt;% filter(t &lt;= tmax)
    max_rid &lt;- nrow(df_it)
  
    # into a list
    MyData &lt;- list(K=K, PGF=PGF, 
                   X=efunctions_scaled[1: max_rid, ], 
                   mon.names=mon.names,
                   parm.names=parm.names, 
                   pos.xi=pos.xi, 
                   y=df_it$Y, 
                   tao=diag(evalues_scaled), f0=mu_new[1:max_rid, ])
    
    
    # fit laplace approximation
    Fit &lt;- LaplaceApproximation(Model, parm = rep(0, K), Data=MyData, Method = &quot;BFGS&quot;)
    # Fit &lt;- LaplacesDemon(Model, Data=MyData, Initial.Values = parm = rep(0, K),  Method = &quot;BFGS&quot;)
    score &lt;- Fit$Summary1[, &quot;Mode&quot;]
    
    # prediction
    eta_pred_out &lt;- mu_new+efunctions_scaled%*%score
    df_i[ , paste0(&quot;pred&quot;, tmax)] &lt;- eta_pred_out[,1]
  }
  
  # df_i$pred0.2[df_i$t&lt;=0.2] &lt;- NA
  # df_i$pred0.4[df_i$t&lt;=0.4] &lt;- NA
  # df_i$pred0.6[df_i$t&lt;=0.6] &lt;- NA
  # df_i$pred0.8[df_i$t&lt;=0.8] &lt;- NA
  
  pred_list3[[i]] &lt;- df_i
}</code></pre>
<pre class="r"><code>df_pred3 &lt;- bind_rows(pred_list3)

df_pred3$pred0.2[df_pred3$t&lt;=0.2] &lt;- NA
df_pred3$pred0.4[df_pred3$t&lt;=0.4] &lt;- NA
df_pred3$pred0.6[df_pred3$t&lt;=0.6] &lt;- NA
df_pred3$pred0.8[df_pred3$t&lt;=0.8] &lt;- NA
# overview of predicted track
p3 &lt;- df_pred3 %&gt;%
  filter(id %in% rand_test_id) %&gt;%
  mutate_at(vars(eta_i, pred0.2, pred0.4, pred0.6, pred0.8), function(x){exp(x)/(1+exp(x))}) %&gt;%
  ggplot()+
  geom_point(aes(x=t, y=Y), size = 0.2)+
  geom_line(aes(x=t, y=eta_i, col = &quot;True&quot;))+
  geom_line(aes(x=t, y=pred0.2, col = &quot;0.2&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.4, col = &quot;0.4&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.6, col = &quot;0.6&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  geom_line(aes(x=t, y=pred0.8, col = &quot;0.8&quot;), linetype=&quot;dashed&quot;, na.rm=T)+
  facet_wrap(~id)+
  labs(title = &quot;Scaled, unbiased eigenvalues&quot;)</code></pre>
<pre class="r"><code>t_1sim &lt;- (t_local_glmm+t_fpca+t_debias+t_pred)</code></pre>
<ul>
<li>Time spent on one iteration: 200.33 seconds</li>
<li>Did debiased eigenvalues improve performance? The lines above look
like so. I also wanna see the squared errors and AUC.</li>
<li>Scaling eigenfunctions and values will change a prediction a little
bit</li>
</ul>
<pre class="r"><code>ggarrange(p1, p2, p3, nrow = 1, common.legend = T)</code></pre>
<p><img src="ProgressReportSim_files/figure-html/unnamed-chunk-27-1.png" width="1440" /></p>
</div>
</div>
<div id="ise" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> ISE</h2>
<pre class="r"><code># calcualte ISE
err1 &lt;- df_pred %&gt;%
  mutate(err1 = (pred0.2-eta_i)^2,
         err2 = (pred0.4-eta_i)^2,
         err3 = (pred0.6-eta_i)^2,
         err4 = (pred0.8-eta_i)^2) %&gt;%
  select(id, t, starts_with(&quot;err&quot;))

err1$window = cut(err1$t, breaks = seq(0, 1, by = 0.2), include.lowest = T)
# table(err1$window)
err1 &lt;- split(err1, f = err1$window)

tb1 &lt;- lapply(err1, function(x){
  x %&gt;%  group_by(id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;%
    summarise_at(vars(err1, err2, err3, err4), mean)
}) %&gt;% bind_rows(.id = &quot;Window&quot;)</code></pre>
<pre class="r"><code># calcualte ISE
err2 &lt;- df_pred2 %&gt;%
  mutate(err1 = (pred0.2-eta_i)^2,
         err2 = (pred0.4-eta_i)^2,
         err3 = (pred0.6-eta_i)^2,
         err4 = (pred0.8-eta_i)^2) %&gt;%
  select(id, t, starts_with(&quot;err&quot;))

err2$window = cut(err2$t, breaks = seq(0, 1, by = 0.2), include.lowest = T)
# table(err1$window)
err2 &lt;- split(err2, f = err2$window)

tb2 &lt;- lapply(err2, function(x){
  x %&gt;%  group_by(id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;%
    summarise_at(vars(err1, err2, err3, err4), mean)
}) %&gt;% bind_rows(.id = &quot;Window&quot;)</code></pre>
<pre class="r"><code># calcualte ISE
err3 &lt;- df_pred3 %&gt;%
  mutate(err1 = (pred0.2-eta_i)^2,
         err2 = (pred0.4-eta_i)^2,
         err3 = (pred0.6-eta_i)^2,
         err4 = (pred0.8-eta_i)^2) %&gt;%
  select(id, t, starts_with(&quot;err&quot;))

err3$window = cut(err3$t, breaks = seq(0, 1, by = 0.2), include.lowest = T)
# table(err1$window)
err3 &lt;- split(err3, f = err3$window)

tb3 &lt;- lapply(err3, function(x){
  x %&gt;%  group_by(id) %&gt;% 
    summarise_at(vars(err1, err2, err3, err4), sum) %&gt;%
    summarise_at(vars(err1, err2, err3, err4), mean)
}) %&gt;% bind_rows(.id = &quot;Window&quot;)</code></pre>
<pre class="r"><code># calcualte ISE
options(knitr.kable.NA = &quot;&quot;)

ise &lt;- full_join(tb1, tb2, by = &quot;Window&quot;) %&gt;% full_join(tb3, by = &quot;Window&quot;)
colnames(ise) &lt;-c(&quot;Window&quot;,  rep(seq(0.2, 0.8, by =0.2), 3))
ise %&gt;%
  kable(digits = 3, table.attr = &quot;style = \&quot;color: black;\&quot;&quot;) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot; &quot;= 1, &quot;Unscaled, debiased&quot; = 4, &quot;Unscaled, biased&quot; = 4, &quot;Scaled, debiased&quot; = 4)) %&gt;%
  add_header_above(c(&quot; &quot;=1, &quot;Maximum observation time&quot; = 12))</code></pre>
<table style="color: black; width: auto !important; margin-left: auto; margin-right: auto;" class="table">
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="12">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Maximum observation time
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Unscaled, debiased
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Unscaled, biased
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Scaled, debiased
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Window
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
[0,0.2]
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.2,0.4]
</td>
<td style="text-align:right;">
150.400
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
150.579
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
156.552
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.4,0.6]
</td>
<td style="text-align:right;">
191.892
</td>
<td style="text-align:right;">
76.114
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
199.633
</td>
<td style="text-align:right;">
92.759
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
194.959
</td>
<td style="text-align:right;">
78.384
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.6,0.8]
</td>
<td style="text-align:right;">
224.502
</td>
<td style="text-align:right;">
53.567
</td>
<td style="text-align:right;">
18.183
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
225.410
</td>
<td style="text-align:right;">
60.660
</td>
<td style="text-align:right;">
18.956
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
229.040
</td>
<td style="text-align:right;">
55.995
</td>
<td style="text-align:right;">
18.863
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.8,1]
</td>
<td style="text-align:right;">
118.008
</td>
<td style="text-align:right;">
88.588
</td>
<td style="text-align:right;">
22.542
</td>
<td style="text-align:right;">
13.465
</td>
<td style="text-align:right;">
125.854
</td>
<td style="text-align:right;">
102.200
</td>
<td style="text-align:right;">
24.064
</td>
<td style="text-align:right;">
14.555
</td>
<td style="text-align:right;">
117.566
</td>
<td style="text-align:right;">
94.796
</td>
<td style="text-align:right;">
23.067
</td>
<td style="text-align:right;">
13.683
</td>
</tr>
</tbody>
</table>
<ul>
<li>Looks like the debiased eigenvalues helped.</li>
<li>Scaling, on the other hand, does seem to help in general.</li>
</ul>
</div>
<div id="auc" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> AUC</h2>
<pre class="r"><code># calcualte AUC
auc_df1 &lt;- df_pred %&gt;%
  mutate(window = cut(t, breaks = seq(0, 1, by = 0.2), include.lowest = T)) %&gt;%
  select(Y, starts_with(&quot;pred&quot;), window)

obs_track &lt;- seq(0.2, 0.8, by = 0.2)
pred_window &lt;- unique(auc_df1$window)
auc_mat &lt;- matrix(NA, length(pred_window), length(obs_track))

for(j in seq_along(obs_track)){
  for(i in (j+1):5){
    this_Y &lt;- auc_df1$Y[auc_df1$window==pred_window[i]]
    this_pred &lt;- auc_df1[auc_df1$window==pred_window[i],
                         paste0(&quot;pred&quot;, obs_track[j])]
    this_perf &lt;- performance(prediction(this_pred, this_Y), measure = &quot;auc&quot;)
    auc_mat[i ,j] &lt;- this_perf@y.values[[1]]
  }
}</code></pre>
<pre class="r"><code># calcualte AUC
auc_df2 &lt;- df_pred2 %&gt;%
  mutate(window = cut(t, breaks = seq(0, 1, by = 0.2), include.lowest = T)) %&gt;%
  select(Y, starts_with(&quot;pred&quot;), window)

auc_mat2 &lt;- matrix(NA, length(pred_window), length(obs_track))

for(j in seq_along(obs_track)){
  for(i in (j+1):5){
    this_Y &lt;- auc_df2$Y[auc_df2$window==pred_window[i]]
    this_pred &lt;- auc_df2[auc_df2$window==pred_window[i],
                         paste0(&quot;pred&quot;, obs_track[j])]
    this_perf &lt;- performance(prediction(this_pred, this_Y), measure = &quot;auc&quot;)
    auc_mat2[i ,j] &lt;- this_perf@y.values[[1]]
  }
}</code></pre>
<pre class="r"><code># calcualte AUC
auc_df3 &lt;- df_pred3 %&gt;%
  mutate(window = cut(t, breaks = seq(0, 1, by = 0.2), include.lowest = T)) %&gt;%
  select(Y, starts_with(&quot;pred&quot;), window)


auc_mat3 &lt;- matrix(NA, length(pred_window), length(obs_track))

for(j in seq_along(obs_track)){
  for(i in (j+1):5){
    this_Y &lt;- auc_df3$Y[auc_df3$window==pred_window[i]]
    this_pred &lt;- auc_df3[auc_df3$window==pred_window[i],
                         paste0(&quot;pred&quot;, obs_track[j])]
    this_perf &lt;- performance(prediction(this_pred, this_Y), measure = &quot;auc&quot;)
    auc_mat3[i ,j] &lt;- this_perf@y.values[[1]]
  }
}</code></pre>
<pre class="r"><code># calcualte ISE
options(knitr.kable.NA = &quot;&quot;)

auc &lt;- cbind(auc_mat, auc_mat2, auc_mat3)
rownames(auc) &lt;- unique(auc_df1$window)
colnames(auc) &lt;-c(rep(seq(0.2, 0.8, by = 0.2), 3))
auc %&gt;%
  kable(digits = 3, table.attr = &quot;style = \&quot;color: black;\&quot;&quot;) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot; &quot;= 1, &quot;Unscaled, debiased&quot; = 4, &quot;Unscaled, biased&quot; = 4, &quot;Scaled, debiased&quot; = 4)) %&gt;%
  add_header_above(c(&quot; &quot;=1, &quot;Maximum observation time&quot; = 12))</code></pre>
<table style="color: black; width: auto !important; margin-left: auto; margin-right: auto;" class="table">
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="12">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Maximum observation time
</div>
</th>
</tr>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Unscaled, debiased
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Unscaled, biased
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Scaled, debiased
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
<th style="text-align:right;">
0.2
</th>
<th style="text-align:right;">
0.4
</th>
<th style="text-align:right;">
0.6
</th>
<th style="text-align:right;">
0.8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
[0,0.2]
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.2,0.4]
</td>
<td style="text-align:right;">
0.737
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.736
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.735
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.4,0.6]
</td>
<td style="text-align:right;">
0.666
</td>
<td style="text-align:right;">
0.744
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.663
</td>
<td style="text-align:right;">
0.739
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.664
</td>
<td style="text-align:right;">
0.744
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.6,0.8]
</td>
<td style="text-align:right;">
0.701
</td>
<td style="text-align:right;">
0.782
</td>
<td style="text-align:right;">
0.795
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.700
</td>
<td style="text-align:right;">
0.780
</td>
<td style="text-align:right;">
0.795
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.698
</td>
<td style="text-align:right;">
0.783
</td>
<td style="text-align:right;">
0.795
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
(0.8,1]
</td>
<td style="text-align:right;">
0.753
</td>
<td style="text-align:right;">
0.768
</td>
<td style="text-align:right;">
0.797
</td>
<td style="text-align:right;">
0.8
</td>
<td style="text-align:right;">
0.751
</td>
<td style="text-align:right;">
0.764
</td>
<td style="text-align:right;">
0.797
</td>
<td style="text-align:right;">
0.8
</td>
<td style="text-align:right;">
0.753
</td>
<td style="text-align:right;">
0.767
</td>
<td style="text-align:right;">
0.797
</td>
<td style="text-align:right;">
0.8
</td>
</tr>
</tbody>
</table>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ying Jin" />

<meta name="date" content="2023-09-15" />

<title>Progress Report</title>

<script src="ProgressReport_files/header-attrs-2.21/header-attrs.js"></script>
<script src="ProgressReport_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="ProgressReport_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="ProgressReport_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="ProgressReport_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="ProgressReport_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="ProgressReport_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="ProgressReport_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="ProgressReport_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="ProgressReport_files/navigation-1.1/tabsets.js"></script>
<script src="ProgressReport_files/navigation-1.1/codefolding.js"></script>
<link href="ProgressReport_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="ProgressReport_files/highlightjs-9.12.0/highlight.js"></script>
<script src="ProgressReport_files/kePrint-0.0.1/kePrint.js"></script>
<link href="ProgressReport_files/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Progress Report</h1>
<h4 class="author">Ying Jin</h4>
<h4 class="date">2023-09-15</h4>

</div>


<div id="nhanes-data" class="section level1" number="1">
<h1><span class="header-section-number">1</span> NHANES data</h1>
<div id="data-overview" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Data overview</h2>
<ul>
<li>8763 subjects, 1440 measures each</li>
<li>no missingness</li>
</ul>
<pre class="r"><code>N &lt;- length(unique(df$SEQN)) # sample size 8763
J &lt;- max(df$sind) # 1440 measures per subject</code></pre>
<pre class="r"><code>rand_id &lt;- sample(unique(df$SEQN), size = 4) # &quot;toy&quot; sample

df %&gt;% 
  filter(SEQN %in% rand_id) %&gt;%
  ggplot()+
  geom_point(aes(x=sind, y=Z), size = 0.5)+
  facet_wrap(~SEQN)+
  labs(x=&quot;Time&quot;, y = &quot;Activity&quot;, title = &quot;A brief overview of the outcome&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="fgfpca-estimation" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> fGFPCA
Estimation</h2>
<pre class="r"><code># code
source(here(&quot;Code/GLMM-FPCA.R&quot;)) 
# use pred_latent function to estimate latent function 
source(here(&quot;Code/OutSampMLE.R&quot;))
# source(here(&quot;Code/OutsampBayes.R&quot;))</code></pre>
<div id="binning" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Binning</h3>
<ul>
<li>Bin every 10 measures</li>
</ul>
<pre class="r"><code># bin data
bin_w &lt;- 10 # bin width
n_bin &lt;- J/bin_w # number of bins
brks &lt;- seq(0, J, by = bin_w) # cutoff points
mid &lt;- (brks+bin_w/2)[1:n_bin] # mid points


df$bin &lt;- cut(df$sind, breaks = brks, include.lowest = T, labels = mid)
df$bin &lt;- as.numeric(as.character(df$bin))
# head(df)

df %&gt;% 
  filter(SEQN %in% rand_id) %&gt;%
  group_by(SEQN, bin) %&gt;%
  summarise(num = sum(Z)) %&gt;%
  ggplot()+
  geom_point(aes(x=bin, y=num), size = 0.5)+
  facet_wrap(~SEQN)+
  labs(x=&quot;Time&quot;, y = &quot;Activity&quot;, title = &quot;Number of active nimutes within each bin&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="local-glmms" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Local GLMMs</h3>
<p>Following up on last report, when using glmer, the results from PRILS
(nAGQ=0) seems more in line with experiences. As validation, let’s fit
the marginal model and look at the estimated population-average latent
function, and compare it with the FPCA mean function. Specifically, at
bin s the model would be <span
class="math inline">\(g(E(Y_i(s)))=f_0(s)\)</span>, with no
subject-specific random effect.</p>
<p>Another validation I came up with is to look at the local intercepts.
That is the <span class="math inline">\(\beta_0(s)\)</span> in local
mixed models <span
class="math inline">\(g(E(Y_i(s)))=\beta_0(s)+b_i(x)\)</span>. This
should correspond to the FPCA mean functions, as the population average
level.</p>
<p>Since the individual random effects are centered around zero, I
believe the marginal <span class="math inline">\(f_0(s)\)</span> should
look very much like the conditional <span
class="math inline">\(\beta_0(x)\)</span> if the model local fit well.
The result obviously is in favor of PRILS.n <em>But what is the reason
for AGQ to overshoot downward?</em></p>
<pre class="r"><code># split by each bin
df &lt;- df %&gt;% rename(id = SEQN, Y=Z)
df_bin_lst &lt;- split(df, f = df$bin)</code></pre>
<pre class="r"><code># local marginal GLM
local_marg &lt;- function(df){
    this_glm &lt;- glm(Y ~ 1, data = df, family = binomial)
    eta_hat &lt;- predict(this_glm, type = &quot;link&quot;)
    df$eta_hat &lt;- eta_hat
    return(df)
}

df_est_local_marg &lt;- lapply(df_bin_lst, function(x){local_marg(x)}) 

# local conditional GLMM
## PIRLS vs AGQ
df_est_cond_mean_pirls &lt;- lapply(df_bin_lst, function(x){mean_latent(x, n_node = 0)}) 
df_est_cond_mean_agq &lt;- lapply(df_bin_lst, function(x){mean_latent(x, n_node = 5)}) </code></pre>
<pre class="r"><code>ggarrange(
df_est_local_marg %&gt;% bind_rows() %&gt;%
  select(bin, eta_hat) %&gt;% distinct(.) %&gt;%
  ggplot(aes(x=bin, y=eta_hat))+
  geom_line()+
  labs(x=&quot;local GLM (marginal)&quot;, y = &quot;latent mean&quot;)+
  ylim(-25, 1),

data.frame(bin=mid, eta_hat = unlist(df_est_cond_mean_pirls)) %&gt;%
  ggplot(aes(x=bin, y=eta_hat))+
  geom_line()+
  labs(x=&quot;local GLMM (conditional) using PRILS&quot;, y = &quot;latent mean&quot;)+
  ylim(-25, 1),

data.frame(bin=mid, eta_hat = unlist(df_est_cond_mean_agq)) %&gt;%
  ggplot(aes(x=bin, y=eta_hat))+
  geom_line()+
  labs(x=&quot;local GLMM (conditional) using AGQ&quot;, y = &quot;latent mean&quot;)+
  ylim(-25, 1),

nrow = 1, align = &quot;h&quot;
)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-7-1.png" width="1152" /></p>
<p>Let’s for now trust the results from PIRLS more than AGQ, if we are
using glmer.</p>
<pre class="r"><code># fit local GLMM and estimate latent function
# to avoid near-unidentifiability issues, using PIRLS maximization with nAGQ = 0

# fit local models
df_est_latent &lt;- lapply(df_bin_lst, function(x){pred_latent(x, n_node = 0)}) 
df_est_latent &lt;- bind_rows(df_est_latent)

# keep midpoint values
df_est_latent &lt;- df_est_latent %&gt;%
  select(-sind, -Y) %&gt;% distinct(.)</code></pre>
<pre class="r"><code>df %&gt;% 
  filter(id %in% rand_id) %&gt;%
  left_join(df_est_latent, by = c(&quot;id&quot;, &quot;bin&quot;)) %&gt;%
  mutate(eta_hat = exp(eta_hat)/(1+exp(eta_hat))) %&gt;%
  ggplot()+
  geom_line(aes(x=sind, y=eta_hat, group = id))+
  geom_point(aes(x=sind, y = Y, group = id), size = 0.5)+
  facet_wrap(~id, scales = &quot;free&quot;)+
  labs(x = &quot;Time&quot;, y = &quot;Estimated latent function (probablity scale)&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code># overview at estimated latent function
df %&gt;% 
  filter(id %in% rand_id) %&gt;%
  group_by(id, bin) %&gt;%
  summarise(num = sum(Y)) %&gt;%
  left_join(df_est_latent, by = c(&quot;id&quot;, &quot;bin&quot;)) %&gt;%
  # mutate(eta_hat = exp(eta_hat)/(1+exp(eta_hat))) %&gt;%
  ggplot()+
  geom_line(aes(x=bin, y=eta_hat, group = id))+
  geom_point(aes(x=bin, y = num, group = id), size = 0.5)+
  facet_wrap(~id, scales = &quot;free&quot;)+
  labs(x = &quot;Bin&quot;, y = &quot;Estimated latent function/number of active minutes&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div id="an-alternative-glmmtmb" class="section level4"
number="1.2.2.1">
<h4><span class="header-section-number">1.2.2.1</span> An alternative:
glmmTMB</h4>
<p>The default optimizer of glmmTMB is nlminb (quasi-Newton BFGS),
whereas glmer uses bobyaqa (nAGQ=0) or Nelder_Mead (nAGQ&gt;0)?</p>
<p>Let’s first try to re-do the who local GLMM step using glmmTMB. Looks
like no numeric issue occurred. It takes slightly longer time than PIRLS
in glmer</p>
<pre class="r"><code>library(glmmTMB)
# re-fit local GLMM and check numeric issues
try_fit_lst&lt;-list()
t1=Sys.time()
for(i in seq_along(df_bin_lst)){
  # this_glm &lt;- tryCatch({glmer(Y ~ 1 + (1|id), data = df_bin_lst[[i]], family = binomial, nAGQ=5)},
  #                      warning=function(w){NA})
  this_glm &lt;- glmmTMB(Y ~ 1 + (1|id), data = df_bin_lst[[i]], family = binomial)
  try_fit_lst[[i]] &lt;- this_glm
  
}
df_est_latent_tmb &lt;- lapply(try_fit_lst, function(x){predict(x, type = &quot;link&quot;)})
t2=Sys.time()
t_tmb &lt;- t2-t1
# population mean
mean_tmb &lt;- sapply(try_fit_lst, function(x){coef(summary((x)))$cond[1]})</code></pre>
<ul>
<li>Time: 3.21070526838303 minutes</li>
<li>Mean/Intercept function: It looks like glmmTMB estimates lie right
between PIRLS and AGQ! It takes slightly shorter time than PIRLS and
mean function shoots more downward, not as bad as AGQ though.</li>
</ul>
<pre class="r"><code>ggarrange(
df_est_local_marg %&gt;% bind_rows() %&gt;%
  select(bin, eta_hat) %&gt;% distinct(.) %&gt;%
  ggplot(aes(x=bin, y=eta_hat))+
  geom_line()+
  labs(x=&quot;local GLM (marginal)&quot;, y = &quot;latent mean&quot;)+
  ylim(-15, 1),

data.frame(bin=mid, eta_hat = unlist(df_est_cond_mean_pirls)) %&gt;%
  ggplot(aes(x=bin, y=eta_hat))+
  geom_line()+
  labs(x=&quot;local GLMM (conditional) using PRILS (glmer)&quot;, y = &quot;latent mean&quot;)+
  ylim(-15, 1),

data.frame(bin=mid, eta_hat = mean_tmb) %&gt;%
  ggplot(aes(x=bin, y=eta_hat))+
  geom_line()+
  labs(x=&quot;local GLMM (conditional) using glmmTMB&quot;, y = &quot;latent mean&quot;)+
  ylim(-15, 1),

nrow = 1
)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-12-1.png" width="1152" /></p>
<ul>
<li>Individual latent functions</li>
</ul>
<pre class="r"><code>for(i in seq_along(df_est_latent_tmb)){
  df_est_latent_tmb[[i]] &lt;- data.frame(df_bin_lst[[i]], eta_hat = df_est_latent_tmb[[i]])
}

df_est_latent_tmb &lt;- bind_rows(df_est_latent_tmb)

# keep midpoint values
df_est_latent_tmb &lt;- df_est_latent_tmb %&gt;%
  select(-sind, -Y) %&gt;% distinct(.)</code></pre>
<pre class="r"><code>df %&gt;% 
  filter(id %in% rand_id) %&gt;%
  left_join(df_est_latent %&gt;% select(id, bin, eta_hat), by = c(&quot;id&quot;, &quot;bin&quot;)) %&gt;%
  left_join(df_est_latent_tmb %&gt;% select(id, bin, eta_hat) %&gt;% rename(eta_hat_tmb=eta_hat), 
            by = c(&quot;id&quot;, &quot;bin&quot;)) %&gt;%
  mutate_at(vars(eta_hat, eta_hat_tmb), function(x){exp(x)/(1+exp(x))}) %&gt;% 
  ggplot()+
  geom_line(aes(x=sind, y=eta_hat, col = &quot;glmer&quot;, alpha = 0.5))+
  geom_line(aes(x=sind, y=eta_hat_tmb, col = &quot;glmmTMB&quot;, alpha = 0.5))+
  geom_point(aes(x=sind, y = Y), size = 0.5)+
  facet_wrap(~id, scales = &quot;free&quot;)+
  labs(x = &quot;Time&quot;, y = &quot;Estimated latent function (probablity scale)&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-14-1.png" width="1536" /></p>
<pre class="r"><code># overview at estimated latent function
df %&gt;% 
  filter(id %in% rand_id) %&gt;%
  group_by(id, bin) %&gt;%
  summarise(num = sum(Y)) %&gt;%
  left_join(df_est_latent %&gt;% select(id, bin, eta_hat), by = c(&quot;id&quot;, &quot;bin&quot;)) %&gt;%
  left_join(df_est_latent_tmb %&gt;% select(id, bin, eta_hat) %&gt;% rename(eta_hat_tmb=eta_hat), 
            by = c(&quot;id&quot;, &quot;bin&quot;)) %&gt;%
  ggplot()+
  geom_line(aes(x=bin, y=eta_hat, col = &quot;glmer&quot;, alpha = 0.5))+
  geom_line(aes(x=bin, y=eta_hat_tmb, col = &quot;glmmTMB&quot;, alpha = 0.5))+
  geom_point(aes(x=bin, y = num), size = 0.5)+
  facet_wrap(~id, scales = &quot;free&quot;)+
  labs(x = &quot;Time&quot;, y = &quot;Estimated latent function&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-15-1.png" width="1536" /></p>
<p>So it looks like glmmTMB still overshoot downwards. Between the two
methods, the mid-day part (active part for most people) seems to be very
similar. Difference lies mostly at both ends, with consecutive inactive
minutes.</p>
<pre class="r"><code># numeric values of individual latent function
df %&gt;% 
  filter(id %in% rand_id) %&gt;%
  group_by(id, bin) %&gt;%
  summarise(num = sum(Y)) %&gt;%
  left_join(df_est_latent %&gt;% select(id, bin, eta_hat), by = c(&quot;id&quot;, &quot;bin&quot;)) %&gt;%
  left_join(df_est_latent_tmb %&gt;% select(id, bin, eta_hat) %&gt;% rename(eta_hat_tmb=eta_hat), 
            by = c(&quot;id&quot;, &quot;bin&quot;)) %&gt;%
  head(20)</code></pre>
</div>
</div>
<div id="fpca" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> FPCA</h3>
<p>Follow up from late time, let’s use PIRLS estimator and fix the
number of PC functions instead of using all of them. We start with four
PC functions.</p>
<p>I will use estimated latent functions from both glmer (nAGQ=0) and
glmmTMB, and compare their results.</p>
<pre class="r"><code># glmer nAGQ=0
mat_est_unique &lt;- matrix(df_est_latent$eta_hat, nrow=N, ncol=n_bin, byrow = F) 
fpca_mod &lt;- fpca.face(mat_est_unique, argvals = mid, var=T)


# lmmTMB
mat_est_unique2 &lt;- matrix(df_est_latent_tmb$eta_hat, 
                          nrow=N, ncol=n_bin, byrow = F) 
fpca_mod2 &lt;- fpca.face(mat_est_unique2, argvals = mid, var=T)

# ncol(fpca_mod$efunctions) # 27 eigenfunctions
K &lt;- 4</code></pre>
<ul>
<li>Population mean function</li>
</ul>
<p>Hmm…FPCA seems to shoot the population mean downward in both methods,
more so for glmmTMB. It looks like more rounds of model would make the
population mean function more variable. Does that make sense?</p>
<pre class="r"><code># population mean
par(mfrow=c(1, 2))
plot(mid, fpca_mod$mu, type = &quot;l&quot;, xlab = &quot;bin&quot;, ylab = &quot;mean&quot;, main = &quot;glmer&quot;,
     ylim = c(-12, 1))
plot(mid, fpca_mod2$mu, type = &quot;l&quot;, xlab = &quot;bin&quot;, ylab = &quot;mean&quot;, main = &quot;glmmTMB&quot;, ylim = c(-12, 1))</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-18-1.png" width="672" />
- PC functions</p>
<pre class="r"><code># eigenfunctions
par(mfrow=c(4,2))

plot(mid, fpca_mod$efunctions[, 1], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC1&quot;, main = &quot;glmer&quot;, ylim = c(-0.21, 0.13))
plot(mid, fpca_mod2$efunctions[, 1], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC1&quot;, main = &quot;glmmTMB&quot;, ylim = c(-0.21, 0.13))

plot(mid, fpca_mod$efunctions[, 2], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC2&quot;, ylim = c(-0.2, 0.14))
plot(mid, fpca_mod2$efunctions[, 2], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC2&quot;,ylim = c(-0.2, 0.14))

plot(mid, fpca_mod$efunctions[, 3], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC3&quot;, ylim = c(-0.2, 0.2))
plot(mid, fpca_mod2$efunctions[, 3], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC3&quot;,ylim = c(-0.2, 0.2))

plot(mid, fpca_mod$efunctions[, 4], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC4&quot;, ylim = c(-0.14, 0.23))
plot(mid, fpca_mod2$efunctions[, 4], type=&quot;l&quot;, xlab=&quot;bin&quot;, ylab=&quot;PC4&quot;,
     ylim = c(-0.14, 0.23))</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-19-1.png" width="768" /></p>
<ul>
<li>Individual covariance matrix</li>
</ul>
<p>Wow! This covariacne matrix changed a lot from when using all of the
PCs! It still looks cyclic, but now off-diagnoal region seems much more
stable. Fluctuations mostly centered around diagnoal line.</p>
<pre class="r"><code># covariance
heatmap(fpca_mod$VarMats[[which(unique(df_est_latent$id)==rand_id[1])]],
        Rowv = NA, Colv = NA, main = &quot;glmer&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code>heatmap(fpca_mod2$VarMats[[which(unique(df_est_latent$id)==rand_id[1])]],
        Rowv = NA, Colv = NA, main = &quot;glmmTMB&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-20-2.png" width="672" /></p>
</div>
</div>
<div id="dynamic-prediction" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Dynamic
prediction</h2>
<p>Still from last time, we’re gonna focus on Bayes methods now!</p>
<p>We are also going to extend the observed track, so that there are
some variation in the observed data (instead of all zeros). I am going
to start with 9am (540), 1pm (780), 5pm (1020)</p>
<p>Extending the track seems to solve the problem with failed Laplace
Approximation. Not sure. Should try on the full sample.</p>
<pre class="r"><code>df_pred &lt;- df_est_latent %&gt;% filter(id %in% rand_id)
df_pred[, &#39;pred_t540&#39;] &lt;- df_pred[, &#39;pred_t780&#39;] &lt;- df_pred[, &#39;pred_t1020&#39;] &lt;- NA
score_out_mat &lt;- array(NA, dim = c(length(rand_id), K, 3))</code></pre>
<pre class="r"><code># unique id
# prediction for a single subject
source(here(&quot;Code/OutsampBayes.R&quot;))</code></pre>
<pre><code>## 
## Attaching package: &#39;LaplacesDemon&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:lubridate&#39;:
## 
##     dst, interval</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     partial</code></pre>
<pre><code>## 
## Attaching package: &#39;mvtnorm&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:LaplacesDemon&#39;:
## 
##     dmvt, rmvt</code></pre>
<pre class="r"><code># PRILS
for(i in rand_id){
  df_i &lt;- df %&gt;% filter(id==i) 
  
  # prediction 
  ## up to 360
  pred_t1 &lt;- out_pred_laplace(fpca_mod, df_i %&gt;% filter(sind&lt;=540), kpc=K)
  eta_pred_t1 &lt;- fpca_mod$mu+fpca_mod$efunctions[, 1:K]%*%pred_t1$score_out
  df_pred[df_pred$id == i, &#39;pred_t540&#39;] &lt;- eta_pred_t1
  ## up to 720
  pred_t2 &lt;- out_pred_laplace(fpca_mod, df_i %&gt;% filter(sind&lt;=780), kpc=K)
  eta_pred_t2 &lt;- fpca_mod$mu+fpca_mod$efunctions[, 1:K]%*%pred_t2$score_out
  df_pred[df_pred$id == i, &#39;pred_t780&#39;] &lt;- eta_pred_t2
  ## up to 1080
  pred_t3 &lt;- out_pred_laplace(fpca_mod, df_i %&gt;% filter(sind&lt;=1020), kpc = K)
  eta_pred_t3 &lt;- fpca_mod$mu+fpca_mod$efunctions[, 1:K]%*%pred_t3$score_out
  df_pred[df_pred$id == i, &#39;pred_t1020&#39;] &lt;- eta_pred_t3

}

df_pred$pred_t540[df_pred$bin&lt;=540] &lt;- NA
df_pred$pred_t780[df_pred$bin&lt;=780] &lt;- NA
df_pred$pred_t1020[df_pred$bin&lt;=1020] &lt;- NA</code></pre>
<pre class="r"><code># glmmTMB
df_pred2 &lt;- df_est_latent %&gt;% filter(id %in% rand_id)
df_pred2[, &#39;pred_t540&#39;] &lt;- df_pred2[, &#39;pred_t780&#39;] &lt;- df_pred2[, &#39;pred_t1020&#39;] &lt;- NA


for(i in rand_id){
  df_i &lt;- df %&gt;% filter(id==i) 
  
  # prediction 
  ## up to 360
  pred_t1 &lt;- out_pred_laplace(fpca_mod2, df_i %&gt;% filter(sind&lt;=540), kpc=K)
  eta_pred_t1 &lt;- fpca_mod2$mu+fpca_mod2$efunctions[, 1:K]%*%pred_t1$score_out
  df_pred2[df_pred$id == i, &#39;pred_t540&#39;] &lt;- eta_pred_t1
  ## up to 720
  pred_t2 &lt;- out_pred_laplace(fpca_mod2, df_i %&gt;% filter(sind&lt;=780), kpc=K)
  eta_pred_t2 &lt;- fpca_mod2$mu+fpca_mod2$efunctions[, 1:K]%*%pred_t2$score_out
  df_pred2[df_pred$id == i, &#39;pred_t780&#39;] &lt;- eta_pred_t2
  ## up to 1080
  pred_t3 &lt;- out_pred_laplace(fpca_mod2, df_i %&gt;% filter(sind&lt;=1020), kpc = K)
  eta_pred_t3 &lt;- fpca_mod2$mu+fpca_mod2$efunctions[, 1:K]%*%pred_t3$score_out
  df_pred2[df_pred$id == i, &#39;pred_t1020&#39;] &lt;- eta_pred_t3

}

df_pred2$pred_t540[df_pred$bin&lt;=540] &lt;- NA
df_pred2$pred_t780[df_pred$bin&lt;=780] &lt;- NA
df_pred2$pred_t1020[df_pred$bin&lt;=1020] &lt;- NA</code></pre>
<pre class="r"><code>ggarrange(
df_pred %&gt;%
  ggplot()+
  geom_line(aes(x=bin, y=eta_hat, group = id))+
  geom_line(aes(x=bin, y = pred_t540, col = &quot;540&quot;, group = id))+
  geom_line(aes(x=bin, y = pred_t780, col = &quot;780&quot;, group = id))+
  geom_line(aes(x=bin, y = pred_t1020, col = &quot;1020&quot;, group = id))+
  facet_wrap(~id,scales = &quot;free&quot;)+labs(title = &quot;glmer&quot;),

df_pred2 %&gt;%
  ggplot()+
  geom_line(aes(x=bin, y=eta_hat, group = id))+
  geom_line(aes(x=bin, y = pred_t540, col = &quot;540&quot;, group = id))+
  geom_line(aes(x=bin, y = pred_t780, col = &quot;780&quot;, group = id))+
  geom_line(aes(x=bin, y = pred_t1020, col = &quot;1020&quot;, group = id))+
  facet_wrap(~id,scales = &quot;free&quot;)+labs(title = &quot;glmmTMB&quot;),
nrow = 1, common.legend = T)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-24-1.png" width="1536" /></p>
</div>
</div>
<div id="nhanes-data-application-output" class="section level1"
number="2">
<h1><span class="header-section-number">2</span> NHANES data application
output</h1>
<div id="fgfpca" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> fGFPCA</h2>
<ul>
<li>80% (7017) subjects for model fitting, 20% (1753) subjects for
out-of-sample prediction</li>
<li>3.3 minutes spent on model fitting, 20 minutes spent on prediction
(about 0.01 per subject)</li>
<li>Three subjects had failed approximation, all happened with the
shortest observed track</li>
<li>We can either assume that the latent function value is constant
within the same bin, or use linear interpolation to fill in the gaps
between bin midpoints. Here I wanna compare if this choice would make
any different. Also, there are a log of other methods to fill in the
gaps, such as projection.</li>
<li>For linear interpolation, I set the edges to be the closest data
extreme.</li>
</ul>
<pre class="r"><code>load(here(&quot;Data/ApplOutput_fGFPCA.RData&quot;))</code></pre>
<pre class="r"><code># linear interpolation
# remove subjects with numeric problem
df_test_full &lt;- df %&gt;% 
  filter(id %in% unique(df_test$id)) %&gt;%
  filter(!id %in% skip_id) %&gt;%
  left_join(df_test %&gt;% select(id, bin, pred_t540, pred_t780, pred_t1020), by = c(&quot;id&quot;, &quot;bin&quot;))
df_test_full$pred_t540_interp &lt;- df_test_full$pred_t780_interp &lt;- df_test_full$pred_t1020_interp &lt;- NA 

# interpolation for each subject
for(i in unique(df_test_full$id)){
  # interpolation t540
  interp_i_t540 &lt;- approx(x = df_test[df_test$id==i, &quot;bin&quot;], 
                     y = df_test[df_test$id==i, &quot;pred_t540&quot;],
                     xout = 541:J, rule = 2)
  df_test_full$pred_t540_interp[df_test_full$id==i &amp; df_test_full$sind&gt;540] &lt;- interp_i_t540$y
  
  # interpolation t780
  interp_i_t780 &lt;- approx(x = df_test[df_test$id==i, &quot;bin&quot;], 
                     y = df_test[df_test$id==i, &quot;pred_t780&quot;],
                     xout = 781:J, rule = 2)
  df_test_full$pred_t780_interp[df_test_full$id==i &amp; df_test_full$sind&gt;780] &lt;- interp_i_t780$y
  
  # interpolation t1020
  interp_i_t1020 &lt;- approx(x = df_test[df_test$id==i, &quot;bin&quot;], 
                     y = df_test[df_test$id==i, &quot;pred_t1020&quot;],
                     xout = 1021:J, rule = 2)
  df_test_full$pred_t1020_interp[df_test_full$id==i &amp; df_test_full$sind&gt;1020] &lt;- interp_i_t1020$y
}</code></pre>
<p>Let’s look at four subjects as an example:</p>
<pre class="r"><code>rand_id2 &lt;- sample(unique(df_test$id), 4)
# without interpolation, assume constant latent function value in each bin
df_test_full%&gt;% 
  filter(id %in% rand_id2) %&gt;%
  mutate_at(vars(pred_t540, pred_t780, pred_t1020), function(x)exp(x)/(1+exp(x))) %&gt;% 
  ggplot()+
    geom_line(aes(x=bin, y = pred_t540, col = &quot;9am&quot;))+
    geom_line(aes(x=bin, y = pred_t780, col = &quot;1pm&quot;))+
    geom_line(aes(x=bin, y = pred_t1020, col = &quot;5pm&quot;))+
    geom_point(aes(x=bin, y = Y, col = &quot;Outcome&quot;), size = 0.2)+
    facet_wrap(~id)+
    labs(x = &quot;Time&quot;, y = &quot;Estimated latent function (probablity scale)&quot;, 
         title = &quot;Constant latent function within bin&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre class="r"><code># with interpolation
df_test_full%&gt;% 
  filter(id %in% rand_id2) %&gt;%
  mutate_at(vars(pred_t540_interp, pred_t780_interp, pred_t1020_interp), function(x)exp(x)/(1+exp(x))) %&gt;% 
  ggplot()+
    geom_line(aes(x=bin, y = pred_t540_interp, col = &quot;9am&quot;))+
    geom_line(aes(x=bin, y = pred_t780_interp, col = &quot;1pm&quot;))+
    geom_line(aes(x=bin, y = pred_t1020_interp, col = &quot;5pm&quot;))+
    geom_point(aes(x=bin, y = Y, col = &quot;Outcome&quot;), size = 0.2)+
    facet_wrap(~id)+
    labs(x = &quot;Time&quot;, y = &quot;Estimated latent function (probablity scale)&quot;, 
         title = &quot;Interpolated latent function&quot;)</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-28-1.png" width="672" />
- Subjects with numeric issue</p>
<pre class="r"><code>df %&gt;% filter(id %in% skip_id) %&gt;% 
  ggplot()+
  geom_point(aes(x=sind, y=Y), size = 0.2)+
  facet_wrap(~id)+
  geom_vline(xintercept = c(540))</code></pre>
<p><img src="ProgressReport_files/figure-html/unnamed-chunk-29-1.png" width="864" /></p>
<ul>
<li>Calculated AUC</li>
</ul>
<pre class="r"><code># break by prediction window
lst_auc &lt;- df_test_full %&gt;% 
  mutate(window = cut(sind, breaks = c(0, 540, 780, 1020, 1260, 1440), 
                      labels = c(&quot;0-9am&quot;, &quot;9am-1pm&quot;, &quot;1pm-5pm&quot;, &quot;5pm-9pm&quot;,&quot;9pm-12pm&quot;), 
                      include.lowest = T))
lst_auc &lt;- split(lst_auc, f=lst_auc$window)</code></pre>
<pre class="r"><code># no interpolation
# up to 9am
auc_t540 &lt;- lst_auc[2:4] %&gt;% 
  lapply(function(x)performance(prediction(x$pred_t540, x$Y), measure = &quot;auc&quot;))
auc_t540 &lt;- lapply(auc_t540, function(x){x@y.values[[1]]}) %&gt;% unlist()

# up to 1pm
auc_t780 &lt;- lst_auc[3:4] %&gt;% 
  lapply(function(x)performance(prediction(x$pred_t780, x$Y), measure = &quot;auc&quot;))
auc_t780 &lt;- lapply(auc_t780, function(x){x@y.values[[1]]}) %&gt;% unlist()

# up to 5pm
auc_t1020 &lt;- lst_auc[4] %&gt;% 
  lapply(function(x)performance(prediction(x$pred_t1020, x$Y), measure = &quot;auc&quot;))
auc_t1020 &lt;- lapply(auc_t1020, function(x){x@y.values[[1]]}) %&gt;% unlist()</code></pre>
<pre class="r"><code># with interpolation
# up to 9am
auc_t540_interp &lt;- lst_auc[2:4] %&gt;% 
  lapply(function(x)performance(prediction(x$pred_t540_interp, x$Y), measure = &quot;auc&quot;))
auc_t540_interp &lt;- lapply(auc_t540_interp, function(x){x@y.values[[1]]}) %&gt;% unlist()

# up to 1pm
auc_t780_interp &lt;- lst_auc[3:4] %&gt;% 
  lapply(function(x)performance(prediction(x$pred_t780_interp, x$Y), measure = &quot;auc&quot;))
auc_t780_interp &lt;- lapply(auc_t780_interp, function(x){x@y.values[[1]]}) %&gt;% unlist()

# up to 5pm
auc_t1020_interp &lt;- lst_auc[4] %&gt;% 
  lapply(function(x)performance(prediction(x$pred_t1020_interp, x$Y), measure = &quot;auc&quot;))
auc_t1020_interp &lt;- lapply(auc_t1020_interp, function(x){x@y.values[[1]]}) %&gt;% unlist()</code></pre>
</div>
<div id="glmmadaptvie" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> GLMMadaptvie</h2>
<ul>
<li>when fitting model with <strong>random intercept + slope</strong> on
the same full training set: Error: vector memory exhausted (limit
reached?)</li>
<li>when fitting model with <strong>only random intercept</strong> on
the same full training set: Error regarding a large coefficient value.
One fix is to re-scale covariates. So I re-scaled minute index by
dividing them by J, so the range is within (0, 1], and tried again. This
fitting procedure took 20.72 minutes to finish</li>
<li>Out-of-sample prediction took 12.18 minutes. About 0.007 minute per
subject.</li>
</ul>
<pre class="r"><code>load(here(&quot;Data/ApplOutput_GLMMadaptive.RData&quot;))</code></pre>
<pre class="r"><code># up to 540
auc_t540_adglmm &lt;- adglmm_pred_t540$newdata2 %&gt;%
  mutate(sind=sind*J) %&gt;%
  mutate(window = cut(sind, breaks = c(540, 780, 1020, 1260, 1440), 
                      labels = c(&quot;9am-1pm&quot;, &quot;1pm-5pm&quot;, &quot;5pm-9pm&quot;,&quot;9pm-12pm&quot;), 
                      include.lowest = T))
auc_t540_adglmm &lt;- split(auc_t540_adglmm, f=auc_t540_adglmm$window)
auc_t540_adglmm &lt;- auc_t540_adglmm[1:3] %&gt;% 
  lapply(function(x)performance(prediction(x$pred, x$Y), measure = &quot;auc&quot;))
auc_t540_adglmm &lt;- lapply(auc_t540_adglmm, function(x){x@y.values[[1]]}) %&gt;% unlist()

# up to 780
auc_t780_adglmm &lt;- adglmm_pred_t780$newdata2 %&gt;%
  mutate(sind=sind*J) %&gt;%
  mutate(window = cut(sind, breaks = c(780, 1020, 1260, 1440), 
                      labels = c(&quot;1pm-5pm&quot;, &quot;5pm-9pm&quot;,&quot;9pm-12pm&quot;), 
                      include.lowest = T))
auc_t780_adglmm &lt;- split(auc_t780_adglmm, f=auc_t780_adglmm$window)
auc_t780_adglmm &lt;- auc_t780_adglmm[1:2] %&gt;% 
  lapply(function(x)performance(prediction(x$pred, x$Y), measure = &quot;auc&quot;))
auc_t780_adglmm &lt;- lapply(auc_t780_adglmm, function(x){x@y.values[[1]]}) %&gt;% unlist()

# up to 1020
auc_t1020_adglmm &lt;- adglmm_pred_t1020$newdata2 %&gt;%
  mutate(sind=sind*J) %&gt;%
  mutate(window = cut(sind, breaks = c(1020, 1260, 1440), 
                      labels = c(&quot;5pm-9pm&quot;,&quot;9pm-12pm&quot;), 
                      include.lowest = T))
auc_t1020_adglmm &lt;- split(auc_t1020_adglmm, f=auc_t1020_adglmm$window)
auc_t1020_adglmm &lt;- auc_t1020_adglmm[1] %&gt;% 
  lapply(function(x)performance(prediction(x$pred, x$Y), measure = &quot;auc&quot;))
auc_t1020_adglmm &lt;- lapply(auc_t1020_adglmm, function(x){x@y.values[[1]]}) %&gt;% unlist()</code></pre>
</div>
<div id="compare-fgfpca-and-glmmadaptive" class="section level2"
number="2.3">
<h2><span class="header-section-number">2.3</span> Compare fGFPCA and
GLMMadaptive</h2>
<pre class="r"><code>options(knitr.kable.NA = &#39;&#39;)
tb_auc &lt;- data.frame(auc_t540, 
           c(NA, auc_t780), 
           c(NA, NA, auc_t1020), 
           auc_t540_interp, 
           c(NA, auc_t780_interp), 
           c(NA, NA, auc_t1020_interp), 
           auc_t540_adglmm,
           c(NA, auc_t780_adglmm), 
           c(NA, NA, auc_t1020_adglmm))

colnames(tb_auc) &lt;- rep(c(&quot;9am&quot;, &quot;1pm&quot;, &quot;5pm&quot;), 3)

tb_auc %&gt;%
  kable(digit = 4) %&gt;%
  kable_styling(full_width = F) %&gt;% 
  add_header_above(c(&quot;Time spent on model fitting&quot; = 1, &quot;3.3&quot; = 6, &quot;20.72&quot; = 3), bold = F) %&gt;%
  add_header_above(c(&quot;Time spent on prediction&quot; = 1, &quot;20.0&quot; = 6, &quot;12.2&quot; = 3), bold = F) %&gt;% 
  add_header_above(c(&quot; &quot;=1, &quot;fGFPCA&quot;=3, &quot;fGFPCA+interpolation&quot; = 3, &quot;GLMMadaptive&quot;=3))</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
fGFPCA
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
fGFPCA+interpolation
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
GLMMadaptive
</div>
</th>
</tr>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Time spent on prediction
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="6">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
20.0
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
12.2
</div>
</th>
</tr>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Time spent on model fitting
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="6">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
3.3
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
20.72
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
9am
</th>
<th style="text-align:right;">
1pm
</th>
<th style="text-align:right;">
5pm
</th>
<th style="text-align:right;">
9am
</th>
<th style="text-align:right;">
1pm
</th>
<th style="text-align:right;">
5pm
</th>
<th style="text-align:right;">
9am
</th>
<th style="text-align:right;">
1pm
</th>
<th style="text-align:right;">
5pm
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
9am-1pm
</td>
<td style="text-align:right;">
0.7179
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.7178
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.6784
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
1pm-5pm
</td>
<td style="text-align:right;">
0.6188
</td>
<td style="text-align:right;">
0.7463
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.6188
</td>
<td style="text-align:right;">
0.7461
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0.6279
</td>
<td style="text-align:right;">
0.7258
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
5pm-9pm
</td>
<td style="text-align:right;">
0.5915
</td>
<td style="text-align:right;">
0.6340
</td>
<td style="text-align:right;">
0.7127
</td>
<td style="text-align:right;">
0.5915
</td>
<td style="text-align:right;">
0.6339
</td>
<td style="text-align:right;">
0.7127
</td>
<td style="text-align:right;">
0.5832
</td>
<td style="text-align:right;">
0.6377
</td>
<td style="text-align:right;">
0.6799
</td>
</tr>
</tbody>
</table>
<ul>
<li>fGFPCA almost always have higher AUC. It at least is as good as
GLMMadaptive.</li>
<li>Computationally, fGFPCA is about 10 minute faster (33%).</li>
</ul>
</div>
<div id="discussion" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Discussion</h2>
<ul>
<li>What would be the reference method to compare our performance to?
Original GLMMadaptvie perhaps is feasible on teh entire dataset. But
what should we use if we wanna do sub-sample comparison? Should we even
do that for this data application (or simulation alone)?</li>
<li>There are still three folks with numeric problem! Shall we extend
the observation track even more? I suspect that may cause still the same
issue just on different subjects.</li>
<li>Is interplation really necessary? It does not improve performance
very much but consumes time. Also, should I try more sophisticated
methods for grid extension?</li>
</ul>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

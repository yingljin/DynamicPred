---
title: "Problem of Step 4 (debias) of fGFPCA on NHANES data"
author: "Ying Jin"
output: 
  html_document:
    self_contained: yes
    number_sections: true
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
    font: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

set.seed(130)

library(here)
library(tidyverse)
library(ggpubr)
library(refund)
library(lme4)
library(ROCR)
library(GLMMadaptive)
library(kableExtra)
library(mvtnorm)
library(mgcv)
library(splines)
library(LaplacesDemon)
library(arsenal)
theme_set(theme_minimal())
```


```{r}
# load data
df <- read_rds(here("Data/nhanes_bi.rds"))

# code
source(here("Code/GLMM-FPCA.R")) 
# use pred_latent function to estimate latent function 
K <- 4
source(here("Code/OutsampBayes.R"))
```



```{r bin_data}
# head(df)
df <- df %>% rename(id=SEQN, Y=Z)
N <- length(unique(df$id))
Ntr <- 500
J <- length(unique(df$sind))

load(here("Data/Appl_debias_model.RData"))

# parameters used in binning
bin_w <- 10 # bin width
n_bin <- J/bin_w # number of bins
brks <- seq(0, J, by = bin_w) # cutoff points
mid <- (brks+bin_w/2)[1:n_bin] # mid points
```


# Estimates

- Eigenvalues

```{r evals}
evals <- 1/debias_glmm$sp[2:5]/n_bin
```

- PC functions

```{r}
df_phi <- debias_glmm$model %>% select(sind, starts_with("phi")) %>% distinct(.) %>%
  mutate_at(vars(starts_with("phi")), function(x){x*sqrt(n_bin)}) 

df_phi %>% pivot_longer(2:5) %>%
  ggplot(aes(x=sind, y=value))+
  geom_line()+
  facet_wrap(~name)
```

- Mean function

```{r}
mu <- predict(debias_glmm, type = "terms")[1:J, 1]
plot(1:J, mu, type = "l")
```

# Simulation using re-evaluated estimates

```{r gen_data}
# generate score
xi <- rmvnorm(Ntr, mean = rep(0, K), sigma = diag(evals))
xi %>% data.frame() %>% pivot_longer(1:4, names_to = "PC", values_to = "score") %>%
  ggplot()+
  geom_boxplot(aes(x=PC, y=score))+
  geom_jitter(aes(x=PC, y=score), size = 0.5)

# individual random effects
bi <- as.matrix(df_phi[, 2:5]) %*% t(xi)

# add in mean 
eta <- apply(bi, 2, function(x){x+mu})
gen_df <- data.frame(id = factor(rep(1:Ntr, each=J)),
                     sind = rep(1:J, Ntr), 
                     eta_i = as.vector(eta))

# binary outcome
gen_df$Y <- rbinom(Ntr*J, size=1, prob=plogis(gen_df$eta_i))

gen_df %>% filter(id %in% 1:4) %>%
  ggplot()+
  geom_point(aes(x=sind, y=Y), size = 0.5)+
  geom_line(aes(x=sind, y=plogis(eta_i)), col = "red")+
  facet_wrap(~id)+
  labs(title = "Generated data")
```

# fGFPCA on generated data 

```{r fGFPCA1}
# bin 
gen_df$bin <- cut(gen_df$sind, breaks = brks, include.lowest = T, labels = mid)
gen_df$bin <- as.numeric(as.character(gen_df$bin))

# local GLMM
train_bin_lst <- split(gen_df, f = gen_df$bin)
df_est_latent <- lapply(train_bin_lst, function(x){pred_latent(x, n_node = 0)}) 
df_est_latent <- bind_rows(df_est_latent) 

df_est_latent %>% filter(id %in% 1:4) %>%
  ggplot()+
  geom_point(aes(x=sind, y=Y), size = 0.5)+
  geom_line(aes(x=sind, y=plogis(eta_i), col = "True"))+
  geom_line(aes(x=sind, y=plogis(eta_hat), col = "Estimate"))+
  facet_wrap(~id)+
  labs(title = "Generated data")
```


```{r fGFPCA2}
# FPCA
uni_eta_hat <- df_est_latent %>% filter(bin==sind)
mat_est_unique <- matrix(uni_eta_hat$eta_hat, nrow=Ntr, ncol=n_bin, byrow = F) 
fpca_mod <- fpca.face(mat_est_unique, argvals = mid, var=T, npc=K)
```


```{r re_eval_PC}
# interpolation
p <- 3 # order of b splines 
knots <- 35 # number of knots (same from FPCA model)
knots_values <- seq(-p, knots + p, length = knots + 1 + 2 *p)/knots
knots_values <- knots_values * (max(mid) - min(mid)) + min(mid)

B <- spline.des(knots = knots_values, x = mid, ord = p + 1,
                outer.ok = TRUE)$design  # evaluate B-splines on binned grid
Bnew <- spline.des(knots = knots_values, x = 1:J, ord = p + 1,
                   outer.ok = TRUE)$design  # evaluate B-splines on original grid

est_phi <- matrix(NA, J, K) 
for(k in 1:K){
  lm_mod <- lm(fpca_mod$efunctions[,k] ~ B-1)
  est_phi[,k] <- Bnew %*% coef(lm_mod)
} 
colnames(est_phi) <- paste0("phi", 1:K)
```


I would like to look at estimated PC functions:

```{r}
# PC functions after re-evaluation
bind_rows(
  data.frame(sind=1:J, est_phi*sqrt(n_bin), type = "re-evaluated"),
  data.frame(df_phi, type = "True")
) %>%
  pivot_longer(2:5) %>%
  ggplot()+
  geom_line(aes(x=sind, y=value, col=type))+
  facet_wrap(~name)
```

It looks like something went wrong in the estimation of PC3. The estimated line is either identical or off by a sign compared to the true PC functions. That said, PC2 seems a bit off too. 

What about the estimated PC functions from FPCA without re-evaluation? 

```{r}
fpca_phi <- fpca_mod$efunctions*sqrt(n_bin)
colnames(fpca_phi) <- paste0("phi", 1:K)
bind_rows(
  data.frame(df_phi, type = "True"),
  data.frame(sind = mid, fpca_phi, type = "FPCA")
) %>%
  pivot_longer(2:5) %>%
  ggplot()+
  geom_point(aes(x=sind, y=value, col=type),size = 0.5)+
  facet_wrap(~name)
```

Looks like FPCA did not capture the shape of PC2 and PC3. 


Next I'd like to re-evaluate the eigenvalues

```{r}
# debias model
gen_df <- gen_df %>% 
  left_join(df_phi, by = "sind")
gen_df$id <- as.factor(gen_df$id)
debias_glmm2 <- bam(Y ~ s(sind, bs="cr")+
                   s(id, by=phi1, bs="re")+
                   s(id, by=phi2, bs="re")+
                   s(id, by=phi3, bs="re")+
                   s(id, by=phi4, bs="re"),
                 family = binomial,
                 data=gen_df,
                 method = "fREML",
                 discrete = TRUE)
```

Eigenvalues before and after re-evaluation

```{r, class.source='fold-show'}
# fpca
fpca_mod$evalues/n_bin

# re-evaluated
1/debias_glmm2$sp[2:5]
```

It looks like the flip happened again. 

At this point, I think we could say the reversed eigenvalue problem is an artifact of the dataset it self. For some reason, FPCA was not able to estimated PC2 and PC3 very well, and the GLMM model later on impose more penalty on the second random term.  
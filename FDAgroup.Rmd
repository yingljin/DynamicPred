---
title: "Dynamic Prediction with fPCA "
output: beamer_presentation
date: "2022-11-3"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(fcr)
library(face)
library(refund)
library(ggplot2)
library(tidyverse)

set.seed(1025)

df = content
df_train = subset(content, include == 1)
df_test = subset(content, include == 0)
```

## Dynamic prediction 

- With observations up to $t_m$, predict outcomes (or probabilities of outcome) after that time point
- Prediction updates with new observations


## Functional Concurrent Regression (FCR)

- Goal: to predict future track based on observed track

- For a subject i, we observe a function over t
$$Y_i(t)=f_0(t)+b_i(t)+\epsilon_i(t)$$
- We usually observe $Y_i$ on a series of discrete $t_{ij}$

$$Y_{ij} = f_0(t_{ij})+b_i(t_{ij})+\epsilon_{ij}, \hspace{0.5cm} j = 1...J_i$$
where $\epsilon_{ij} \sim N(0, \sigma_{\epsilon^2})$.

- Subject-specific random effect

$$b_i(t) = \Sigma_{k=1}^c u_{ik}B_k(t)$$
where $\boldsymbol{u_i}\sim N(0, \Gamma)$


## Dynamic prediction

- When there is no covariate in the model, this is essentially a fPCA problem.

  - $\boldsymbol{B}$ is a matrix of eigenfunctions
  - $\boldsymbol{u}$ is a matrix of PC scores/loadings

- Use fPCA to estimate $f_0$, $\Gamma$ and $\sigma_{\epsilon}$


- For a new subject with observations up to $t_m$, estimate its score: 

$$\hat{\boldsymbol{u}} = E(\boldsymbol{u}|\boldsymbol{y}) =  \boldsymbol{\hat{\Gamma}B^T}(\boldsymbol{B\hat{\Gamma}B^T}+\hat{\sigma_{\epsilon}}^2\boldsymbol{I_m})$$
With the estimated score, we can predict its outcome in following time points

$$\hat{\boldsymbol{Y}} = \hat{\boldsymbol{f}}_0+ \boldsymbol{B}^T\hat{\boldsymbol{u}} $$


## Simulated child growth data

- Predict length-for-age, observed with noise


```{r}
ggplot(df %>% filter(subj%in% 1:10), aes(x=argvals, y=Y, group = subj, col = as.factor(subj)))+
  geom_line(show.legend = F)+
  labs(title = "Length-for-Age for the first 10 subjects",
       x = "time")
``` 


## FPCA on observed LAZ

```{r}
tnew = sort(unique(df_train$argvals))
df_laz <- df_train %>% select(argvals, subj, Y) %>%
  rename("y" = "Y")
fpca_laz <- face.sparse(df_laz, newdata = df_laz, knots = 15, argvals.new = tnew, calculate.scores = TRUE)

# mean function

par(mfrow = c(2, 2))
plot(tnew, fpca_laz$mu.new, type = "l", 
     xlab = "t", ylab = "f0(t)")
plot(tnew, fpca_laz$eigenfunctions[, 1], type = "l", xlab = "t", ylab = "PC1")
plot(tnew, fpca_laz$eigenfunctions[, 2], type = "l", xlab = "t", ylab = "PC2")
plot(tnew, fpca_laz$eigenfunctions[, 3], type = "l", xlab = "t", ylab = "PC3")




```

## Prediction of new partially observed sample

```{r, pred_func}
# write a function for prediction up to t
# df_test: datafram with columns argvals, subj, y, observation up to tm


DynPred <- function(df_test = df_test1, tm = 0.3, fpca_fit = fpca_laz){
  Ntest = length(unique(df_test$subj))
  # prediction
  pred1 <- predict(fpca_fit, newdata = df_test)
  # Eigen functions
  Bnew <- fpca_fit$eigenfunctions[fpca_fit$argvals.new > tm, ]
  Yhat <- fpca_fit$mu.new[fpca_fit$argvals.new > tm] + Bnew%*%t(pred1$rand_eff$scores)
  # every column is a new function
  Yhat <- data.frame(Yhat)
  colnames(Yhat) <- pred1$rand_eff$subj
  df_pred <- Yhat %>% 
    mutate(argvals = fpca_fit$argvals.new[fpca_fit$argvals.new > tm]) %>% 
    pivot_longer(all_of(1:Ntest), names_to = "subj", values_to = "y") %>%
    mutate(type = "pred")
  
  return(df_pred)
}
```


```{r t0_3}
df_test_t0.3 <- DynPred(df_test %>%  select(argvals, subj, Y) %>%
  rename("y" = "Y") %>% 
  filter(argvals <= 0.3))

# figure 
bind_rows(df_test %>% 
            select(argvals, subj, Y)%>% 
            rename("y" = "Y") %>% 
            mutate(type = "true", subj = as.factor(subj)), 
          df_test_t0.3 %>% mutate(subj = as.factor(subj))) %>% 
  filter(subj %in% 151:156) %>% 
  ggplot(aes(x = argvals, y = y, col = type))+
  geom_line()+
  facet_wrap(~subj)+
  labs(title = "Prediction with observation up to t=0.3", 
       x = "time", y = "")
```

## Prediction of new partially observed sample

```{r}
df_test_t0.5 <- DynPred(df_test %>%  select(argvals, subj, Y) %>%
  rename("y" = "Y") %>% 
  filter(argvals <= 0.5), tm = 0.5)

# figure 

bind_rows(df_test %>% 
            select(argvals, subj, Y)%>% 
            rename("y" = "Y") %>% 
            mutate(type = "true", subj = as.factor(subj)), 
          df_test_t0.5 %>% mutate(subj = as.factor(subj))) %>% 
  filter(subj %in% 151:156) %>% 
  ggplot(aes(x = argvals, y = y, col = type))+
  geom_line()+
  facet_wrap(~subj)+
  labs(title = "Prediction with observation up to t=0.5", 
       x = "time", y = "")

```

## Prediction of new partially observed sample

```{r}
df_test_t0.8 <- DynPred(df_test %>%  select(argvals, subj, Y) %>%
  rename("y" = "Y") %>% 
  filter(argvals <= 0.8), tm = 0.8)

# figure 
bind_rows(df_test %>% 
            select(argvals, subj, Y)%>% 
            rename("y" = "Y") %>% 
            mutate(type = "true", subj = as.factor(subj)), 
          df_test_t0.8 %>% mutate(subj = as.factor(subj))) %>% 
  filter(subj %in% 151:156) %>% 
  ggplot(aes(x = argvals, y = y, col = type))+
  geom_line()+
  facet_wrap(~subj)+
  labs(title = "Prediction with observation up to t=0.8", 
       x = "time", y = "")

```

## Next steps

- Establish interval prediction
- ? fPCA on pooled prediction, instead of original functions observed with noise
- Extension to exponential family data